<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
  <title>
    Publications // Jianbo Jiao
  </title>

  <link href="http://gmpg.org/xfn/11" rel="profile">
<meta http-equiv="content-type" content="text/html; charset=utf-8">


<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

<meta name="description" content="">
<meta name="keywords" content="">
<meta name="author" content="">
<meta name="generator" content="Hugo 0.49" />

  <meta property="og:title" content="Publications" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:locale" content="en_US" />
<meta property="og:url" content="https://jianbojiao.github.io/post/_publications/" />


  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.5.0/base-min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.5.0/pure-min.css">
  
  
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.5.0/grids-responsive-min.css">
  
  

  <link rel="stylesheet" href="https://jianbojiao.github.io//css/redlounge.css">
  <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet">
  <link rel="stylesheet" href="https://jianbojiao.github.io//css/academicons.min.css">
  <link href='//fonts.googleapis.com/css?family=Raleway:400,200,100,700,300,500,600,800' rel='stylesheet' type='text/css'>
  <link href='//fonts.googleapis.com/css?family=Libre+Baskerville:400,700,400italic' rel='stylesheet' type='text/css'>

  
  
  

  <link rel="apple-touch-icon-precomposed" sizes="104x144" href="big.png">
  <link rel="shortcut icon" type="image/x-icon" href="small3.png">

  
  <link href="" rel="alternate" type="application/rss+xml" title="Jianbo Jiao" />

    
  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.7/styles/tomorrow-night-bright.min.css">
  
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.7/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>


  

  

  

  
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', "UA-102110812-1", 'auto');
  ga('send', 'pageview');
</script>

</head>

<body>
	

	<div id="layout" class="pure-g">
    <div class="sidebar pure-u-1 pure-u-md-1-4">
  <div class="header">
    

	

    <h1 class="brand-title">Jianbo Jiao</h1>
    <h2 class="brand-tagline">Royal Society Short Industry Fellow</h2>
    <h2 class="brand-tagline">Fellow of the HEA</h2>
    <h2 class="brand-tagline">Assistant Professor</h2>
    <h2 class="brand-tagline">School of Computer Science</h2>
    <h2 class="brand-tagline">University of Birmingham</h2>

    <nav class="nav">
      <ul class="nav-list">
        <li class="nav-item"><span class="nav-item-separator">//</span><a href="https://jianbojiao.github.io/">Home</a></li>
        
          <li class="nav-item"><span class="nav-item-separator">//</span><a href="https://scholar.google.com/citations?user=HkEiMMwAAAAJ&amp;hl=en">Google Scholar</a></li>
        
          <li class="nav-item"><span class="nav-item-separator">//</span><a href="https://mix.jianbojiao.com/">Group</a></li>
        
          <li class="nav-item"><span class="nav-item-separator">//</span><a href="https://www.linkedin.com/in/JianboJiao/">LinkedIn</a></li>
        
          <li class="nav-item"><span class="nav-item-separator">//</span><a href="mailto:j.jiao@bham.ac.uk%20or%20jiaojianbo.i@gmail.com">Email</a></li>
        
          <li class="nav-item"><span class="nav-item-separator">//</span><a href="misc_index.html">Misc</a></li>
        
      </ul>
    </nav>

    

  </div>
</div>


	

    <div class="content pure-u-1 pure-u-md-3-4">
		<a name="top"></a>
		

		
			
	    
  		<section class="post">
            <h1 class="post-title">Publications</h1>
						

            <p><br>
<img align="left" style="width:200px;height:120px;margin:5px 5px" src="img/cvpr24x360.png">
<strong>360+x: A Panoptic Multi-modal Scene Understanding Dataset</strong><br>
<font size=2> Hao Chen, Yuqi Hou, Chenyuan Qu, Irene Testini, Xiaohan Hong, <strong>Jianbo Jiao</strong></font><br>
<font size=2><em>IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> (<strong>CVPR</strong>), <font color=#FF8080><strong>Oral Presentation (3.3%)</strong></font>, 2024</font><br>
<a href="pdfs/cvpr24x360.pdf">[PDF]</a> <a href="bibs/cvpr24x360.bib">[BibTeX]</a> <a href="https://arxiv.org/abs/2404.00989">[arXiv]</a> <a href="https://x360dataset.github.io/">[Project Page]</a>
<br></p>

<p><img align="left" style="width:200px;height:120px;margin:5px 5px" src="img/cvpr24dymvhumans.png">
<strong>DyMVHumans: A Multi-View Video Benchmark for High-Fidelity Dynamic Human Modeling</strong><br>
<font size=2> Xiaoyun Zheng, Liwei Liao, Xufeng Li, <strong>Jianbo Jiao</strong>, Rongjie Wang, Feng Gao, Shiqi Wang, Ronggang Wang</font><br>
<font size=2><em>IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> (<strong>CVPR</strong>), 2024</font><br>
<a href="pdfs/cvpr24dymvhumans.pdf">[PDF]</a> <a href="bibs/cvpr24dymvhumans.bib">[BibTeX]</a> <a href="https://arxiv.org/abs/2403.16080">[arXiv]</a> <a href="https://pku-dymvhumans.github.io/">[Project Page]</a>
<br></p>

<p><img align="left" style="width:200px;height:120px;margin:5px 5px" src="img/wacv24dpt.jpg">
<strong>Disentangled Pre-training for Image Matting</strong><br>
<font size=2>Yanda Li, Zilong Huang, Gang Yu, Ling Chen, <a href="https://weiyc.github.io">Yunchao Wei</a>, <strong>Jianbo Jiao</strong></font><br>
<font size=2><em>IEEE/CVF Winter Conference on Applications of Computer Vision</em> (<strong>WACV</strong>), <font color=#FF8080><strong>Oral Presentation (2.5%)</strong></font>, 2024</font><br>
<a href="pdfs/wacv24dpt.pdf">[PDF]</a> <a href="bibs/wacv24dpt.bib">[BibTeX]</a> <a href="https://github.com/crystraldo/dpt">[Code]</a> <a href="https://crystraldo.github.io/dpt_mat/">[Project Page]</a>
<br></p>

<p><img align="left" style="width:200px;height:100px;margin:5px 5px" src="img/wacv24med.png">
<strong>FreMIM: Fourier Transform Meets Masked Image Modeling for Medical Image Segmentation</strong><br>
<font size=2>Wenxuan Wang*, Jing Wang*, Chen Chen,  <strong>Jianbo Jiao</strong>, Yuanxiu Cai, Shanshan Song, Jiangyun Li</font><br>
<font size=2><em>IEEE/CVF Winter Conference on Applications of Computer Vision</em> (<strong>WACV</strong>), 2024</font><br>
<a href="pdfs/wacv24med.pdf">[PDF]</a> <a href="bibs/wacv24med.bib">[BibTeX]</a> <a href="https://github.com/Rubics-Xuan/FreMIM">[Code]</a> <a href="https://rubics-xuan.github.io/FreMIM/">[Project Page]</a>
<br></p>

<p><img align="left" style="width:200px;height:120px;margin:5px 5px" src="img/tip24_surfacesos.png">
<strong>Surface-SOS: Self-Supervised Object Segmentation via Neural Surface Representation</strong><br>
<font size=2> Xiaoyun Zheng, Liwei Liao, <strong>Jianbo Jiao</strong>, Feng Gao, Ronggang Wang</font><br>
<font size=2><em>IEEE Transactions on Image Processing</em>  (<strong>T-IP</strong>), 2024</font><br>
<a href="pdfs/tip24_surfacesos.pdf">[PDF]</a> <a href="bibs/tip24_surfacesos.bib">[BibTeX]</a> <a href="https://github.com/zhengxyun/Surface-SOS">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:105px;margin:5px 5px" src="img/ISBI24.png">
<strong>Dual Representation Learning from Fetal Ultrasound Video and Sonographer Audio</strong><br>
<font size=2>Mourad Gridach, Mohammad Alsharid, <strong>Jianbo Jiao</strong>, Lior Drukker, Aris Papageorghiou, <a href="http://www.ibme.ox.ac.uk/research/biomedia/people/professor-alison-noble">Alison Noble</a></font><br>
<font size=2><em>IEEE International Symposium on Biomedical Imaging</em> (<strong>ISBI</strong>), 2024</font><br>
<a href="pdfs/ISBI24.pdf">[PDF]</a> <a href="bibs/ISBI24.bib">[BibTeX]</a>
<br></p>

<p><img align="left" style="width:200px;height:100px;margin:5px 5px" src="img/ijcv23.png">
<strong>Inferring Attention Shifts for Salient Instance Ranking</strong><br>
<font size=2>Avishek Siris, <strong>Jianbo Jiao</strong>, Gary K.L. Tam, Xianghua Xie, Rynson W.H. Lau</font><br>
<font size=2><em>International Journal of Computer Vision</em> (<strong>IJCV</strong>), 2023</font><br>
<!-- <font size=2>This paper subsumes our [preliminary work](pdfs/CVPR20.pdf) presented at CVPR 2020.</font><br> -->
<a href="https://link.springer.com/article/10.1007/s11263-023-01906-7">[Article]</a> <a href="bibs/ijcv23.bib">[BibTeX]</a> <a href="https://github.com/SirisAvishek/Attention_Shift_Ranks">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:100px;margin:5px 5px" src="img/iccv23med.png">
<strong>Multi-view Self-supervised Disentanglement for General Image Denoising</strong><br>
<font size=2><a href="https://chqwer2.github.io/">Hao Chen</a>*, <a href="https://chenyuanqu.com/">Chenyuan Qu</a>*, Yu Zhang, Chen Chen, <strong>Jianbo Jiao</strong></font><br>
<font size=2><em>IEEE/CVF International Conference on Computer Vision</em> (<strong>ICCV</strong>), 2023</font><br>
<a href="pdfs/iccv23_med.pdf">[PDF]</a> <a href="https://arxiv.org/abs/2309.05049">[ArXiv]</a> <a href="bibs/iccv23_med.bib">[BibTeX]</a> <a href="https://github.com/chqwer2/Multi-view-Self-supervised-Disentanglement-Denoising">[Code]</a> <a href="https://chqwer2.github.io/MeD/">[Project Page]</a>
<br></p>

<p><img align="left" style="width:200px;height:108px;margin:5px 5px" src="img/iccv23coinseg.png">
<strong>CoinSeg: Contrast Inter- and Intra- Class Representations for Incremental Segmentation</strong><br>
<font size=2>Zekang Zhang, Guangyu Gao, <strong>Jianbo Jiao</strong>, Chi Harold Liu, <a href="https://weiyc.github.io">Yunchao Wei</a></font><br>
<font size=2><em>IEEE/CVF International Conference on Computer Vision</em> (<strong>ICCV</strong>), 2023</font><br>
<a href="pdfs/iccv23_coinseg.pdf">[PDF]</a> <a href="bibs/iccv23_coinseg.bib">[BibTeX]</a> <a href="https://github.com/zkzhang98/CoinSeg">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:115px;margin:5px 5px" src="img/iccv23clmvs.png">
<strong>CL-MVSNet: Unsupervised Multi-view Stereo with Dual-level Contrastive Learning</strong><br>
<font size=2>Kaiqiang Xiong, Rui Peng, Zhe Zhang, Tianxing Feng, <strong>Jianbo Jiao</strong>, Feng Gao, <a href="http://www.ece.pku.edu.cn/index.php?a=show&amp;catid=507&amp;id=48">Ronggang Wang</a></font><br>
<font size=2><em>IEEE/CVF International Conference on Computer Vision</em> (<strong>ICCV</strong>), 2023</font><br>
<a href="pdfs/iccv23_clmvs.pdf">[PDF]</a> <a href="bibs/iccv23_clmvs.bib">[BibTeX]</a> <a href="https://github.com/KaiqiangXiong/CL-MVSNet">[Code]</a> <a href="https://kaiqiangxiong.github.io/CL-MVSNet/">[Project Page]</a>
<br></p>

<p><img align="left" style="width:200px;height:100px;margin:5px 5px" src="img/iccv23diffuse3d.png">
<strong>Diffuse3D: Wide-Angle 3D Photography via Bilateral Diffusion</strong><br>
<font size=2>Yutao Jiang, Yang Zhou, Yuan Liang, Wenxi Liu, <strong>Jianbo Jiao</strong>, Yuhui Quan, <a href="http://www.shengfenghe.com/">Shengfeng He</a></font><br>
<font size=2><em>IEEE/CVF International Conference on Computer Vision</em> (<strong>ICCV</strong>), 2023</font><br>
<a href="pdfs/iccv23_diffuse3d.pdf">[PDF]</a> <a href="bibs/iccv23_diffuse3d.bib">[BibTeX]</a> <a href="https://github.com/yutaojiang1/Diffuse3D">[Code]</a> <a href="https://www.dropbox.com/scl/fi/zhp8q7ertpo49cd1t0hp4/d3d-video.mp4?rlkey=c66kkavd6j7d9ftwye1c2au1a&amp;dl=0">[Video]</a>
<br></p>

<p><img align="left" style="width:200px;height:108px;margin:5px 5px" src="img/bibm.png">
<strong>Bridging the Gap: Cross-modal Knowledge Driven Network for Radiology Report Generation</strong><br>
<font size=2>Beichen Kang, Yun Xiong, <strong>Jianbo Jiao</strong>, Yao Zhang, Xing Jia, Ji Li</font><br>
<font size=2><em>IEEE International Conference on Bioinformatics and Biomedicine</em> (<strong>BIBM</strong>), 2023</font><br>
<a href="pdfs/bibm.pdf">[PDF]</a> <a href="bibs/bibm.bib">[BibTeX]</a> <a href="https://github.com/Kangbeichen/CKNet">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:100px;margin:5px 5px" src="img/softinfo.png">
<strong>Speed Co-Augmentation for Unsupervised Audio-Visual Pre-training</strong><br>
<font size=2><a href="https://laura-wang.github.io/">Jiangliu Wang</a>, <strong>Jianbo Jiao</strong>, <a href="https://ybsong00.github.io">Yibing Song</a>, <a href="https://stepjam.github.io/">Stephen James</a>, Zhan Tong, Chongjian Ge, <a href="https://people.eecs.berkeley.edu/~pabbeel/">Pieter Abbeel</a>, Yun-Hui Liu </font><br>
<font size=2><em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<strong>CVPR</strong>) <a href="https://sightsound.org/"><em>Workshop on Sight and Sound</em></a>, 2023</font><br>
<a href="pdfs/softinfo.pdf">[PDF]</a> <a href="bibs/softinfo.bib">[BibTeX]</a> <a href="./">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:100px;margin:5px 5px" src="img/calince.png">
<strong>Cali-NCE: Boosting Cross-modal Video Representation Learning with Calibrated Alignment</strong><br>
<font size=2><a href="http://nxzhao.com/#">Nanxuan Zhao</a>, <strong>Jianbo Jiao</strong>, <a href="https://weidixie.github.io/index.html">Weidi Xie</a>, <a href="http://dahua.site/">Dahua Lin</a> </font><br>
<font size=2><em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<strong>CVPR</strong>) <a href="https://foundation-model.com/home"><em>Workshop on Foundation Model</em></a>, 2023</font><br>
<a href="pdfs/calince.pdf">[PDF]</a> <a href="bibs/calince.bib">[BibTeX]</a> <a href="https://github.com/nanxuanzhao/Cali-NCE">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:110px;margin:5px 5px" src="img/linr.png">
<strong>Revisiting Implicit Neural Representations in Low-Level Vision</strong><br>
<font size=2>Wentian Xu, <strong>Jianbo Jiao</strong> </font><br>
<font size=2><em>International Conference on Learning Representations</em> (<strong>ICLR</strong>) <a href="https://sites.google.com/view/neural-fields"><em>Neural Fields Workshop</em></a>, 2023</font><br>
<a href="pdfs/linr.pdf">[PDF]</a> <a href="https://arxiv.org/abs/2304.10250">[arXiv]</a> <a href="bibs/linr.bib">[BibTeX]</a> <a href="https://wentxul.github.io/LINR-projectpage/">[Project]</a>
<br></p>

<p><img align="left" style="width:200px;height:100px;margin:5px 5px" src="img/tml4h23.png">
<strong>A Kernel Density Estimation based Quality Metric for Quality Assessment of Obstetric Ultrasound Video</strong><br>
<font size=2>Jong Kwon, <strong>Jianbo Jiao</strong>, Alice Self, J. Alison Noble, Aris Papageorghiou </font><br>
<font size=2><em>International Conference on Learning Representations</em> (<strong>ICLR</strong>) <a href="https://sites.google.com/view/tml4h2023/home"><em>Trustworthy Machine Learning for Healthcare Workshop</em></a>, 2023</font><br>
<a href="pdfs/tml4h.pdf">[PDF]</a> <a href="bibs/tml4h.bib">[BibTeX]</a> <a href="https://github.com/kwon-j/KDE-UltrasoundQA">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:100px;margin:5px 5px" src="img/neurips22.png">
<strong>Mining Unseen Classes via Regional Objectness: A Simple Baseline for Incremental Segmentation</strong><br>
<font size=2>Zekang Zhang, Guangyu Gao, Zhiyuan Fang, <strong>Jianbo Jiao</strong>, <a href="https://weiyc.github.io">Yunchao Wei</a> </font><br>
<font size=2><em>Conference on Neural Information Processing Systems</em> (<strong>NeurIPS</strong>), 2022</font><br>
<a href="https://openreview.net/pdf?id=G1vrYk9uX-_">[PDF]</a> <a href="bibs/neurips22.bib">[BibTeX]</a> <a href="https://github.com/zkzhang98/MicroSeg">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:100px;margin:5px 5px" src="img/eccvw22.png">
<strong>Anatomy-Aware Contrastive Representation Learning for Fetal Ultrasound</strong><br>
<font size=2>Zeyu Fu*, <strong>Jianbo Jiao*</strong>, Robail Yasrab*, Lior Drukker, Aris T. Papageorghiou, <a href="http://www.ibme.ox.ac.uk/research/biomedia/people/professor-alison-noble">Alison Noble</a> (*Equal contribution)</font><br>
<font size=2><em>European Conference on Computer Vision</em> (<strong>ECCV</strong>) <em>Medical Computer Vision Workshop</em>, <font color=#FF8080><strong>Oral Presentation</strong></font> (<a href="img/ECCV_MCV_BestPaperAward.jpeg"><font color="e63946"><strong>Best Paper Award</strong></font></a>), 2022</font><br>
<!-- [[PDF]](pdfs/awcl.pdf) [[BibTeX]](bibs/awcl.bib) -->
<a href="pdfs/awcl.pdf">[PDF]</a> <a href="bibs/awcl.bib">[BibTeX]</a> <a href="https://github.com/JianboJiao/AWCL">[Project]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/bmvc21.gif">
<strong>Quantised Transforming Auto-Encoders: Achieving Equivariance to Arbitrary Transformations in Deep Networks</strong><br>
<font size=2><strong>Jianbo Jiao</strong>, <a href="https://www.robots.ox.ac.uk/~joao/">Jo√£o F. Henriques</a></font><br>
<font size=2><em>British Machine Vision Conference</em> (<strong>BMVC</strong>), 2021</font><br>
<a href="pdfs/bmvc21_qtae.pdf">[PDF]</a> <a href="bibs/bmvc21_qtae.bib">[BibTeX]</a> <a href="https://youtu.be/3Vm5gwfWTro">[Presentation]</a> <a href="https://www.robots.ox.ac.uk/~vgg/research/qtae/">[Project]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/medneurips.png">
<strong>Explainability of Self-Supervised Representation Learning for Medical Ultrasound Video</strong><br>
<font size=2>Kangning Zhang, <strong>Jianbo Jiao</strong>, <a href="http://www.ibme.ox.ac.uk/research/biomedia/people/professor-alison-noble">Alison Noble</a></font><br>
<font size=2><em>Conference on Neural Information Processing Systems Workshop</em> (<a href="https://sites.google.com/view/med-neurips-2021"><em>MedNeurIPS</em></a>), 2021</font><br>
<a href="pdfs/medneurips.pdf">[PDF]</a> <a href="bibs/medneurips.bib">[BibTeX]</a> <a href="srcs/medneurips_poster.jpeg">[Poster]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/tpami21.png">
<strong>Self-Supervised Video Representation Learning by Uncovering Spatio-temporal Statistics</strong><br>
<font size=2><a href="https://laura-wang.github.io/">Jiangliu Wang*</a>, <strong>Jianbo Jiao</strong>*, <a href="https://sites.google.com/site/linchaobao/">Linchao Bao</a>, <a href="http://www.shengfenghe.com/">Shengfeng He</a>, <a href="http://www.ee.columbia.edu/~wliu/">Wei Liu</a>, <a href="http://ri.cuhk.edu.hk/yhliu">Yunhui Liu</a> (*Equal contribution)</font><br>
<font size=2><em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> (<strong>T-PAMI</strong>), 2021</font><br>
<font size=2>This paper subsumes our <a href="pdfs/cvpr_VidMAS.pdf">preliminary work</a> presented at CVPR 2019, with <font color=#FF8080><strong>~30%</strong></font> performance improvement!</font><br>
<a href="pdfs/tpami21.pdf">[PDF]</a> <a href="bibs/tpami21.bib">[BibTeX]</a> <a href="https://github.com/laura-wang/video_repres_sts">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:100px;margin:5px 5px" src="img/neurips21.png">
<strong>Revitalizing CNN Attentions via Transformers in Self-Supervised Visual Representation Learning</strong><br>
<font size=2>Chongjian Ge, Youwei Liang, <a href="https://ybsong00.github.io">Yibing Song</a>, <strong>Jianbo Jiao</strong>, <a href="https://www.juew.org">Jue Wang</a>, <a href="http://luoping.me/">Ping Luo</a> </font><br>
<font size=2><em>Conference on Neural Information Processing Systems</em> (<strong>NeurIPS</strong>), 2021</font><br>
<a href="https://arxiv.org/abs/2110.05340">[PDF]</a> <a href="bibs/neurips21.bib">[BibTeX]</a> <a href="https://github.com/ChongjianGE/CARE">[Project]</a> <a href="https://openreview.net/forum?id=sRojdWhXJx">[OpenReview]</a> <a href="https://mp.weixin.qq.com/s/oGS4XSjO29fHdDQXV1vyvg">[Media Coverage]</a>
<br></p>

<p><img align="left" style="width:200px;height:100px;margin:5px 5px" src="img/iccv21.png">
<strong>Scene Context-Aware Salient Object Detection</strong><br>
<font size=2>Avishek Siris, <strong>Jianbo Jiao</strong>, Gary K.L. Tam, Xianghua Xie, <a href="http://www.cs.cityu.edu.hk/~rynson/">Rynson W.H. Lau</a></font><br>
<font size=2><em>IEEE/CVF International Conference on Computer Vision</em> (<strong>ICCV</strong>), 2021</font><br>
<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Siris_Scene_Context-Aware_Salient_Object_Detection_ICCV_2021_paper.pdf">[PDF]</a> <a href="bibs/ICCV21.bib">[BibTeX]</a> <a href="https://github.com/SirisAvishek/Scene_Context_Aware_Saliency">[Code and Dataset]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/jbhi.png">
<strong>Facial Anatomical Landmark Detection using Regularized Transfer Learning with Application to Fetal Alcohol Syndrome Recognition</strong><br>
<font size=2>Zeyu Fu, <strong>Jianbo Jiao</strong>, Michael Suttie, <a href="http://www.ibme.ox.ac.uk/research/biomedia/people/professor-alison-noble">Alison Noble</a></font><br>
<font size=2><em>IEEE Journal of Biomedical and Health Informatics</em> (<strong>JBHI</strong>), 2021</font><br>
<a href="https://ieeexplore.ieee.org/abstract/document/9531054">[PDF]</a> <a href="bibs/jbhi.bib">[BibTeX]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/tpami21_2.png">
<strong>Affinity Attention Graph Neural Network for Weakly Supervised Semantic Segmentation</strong><br>
<font size=2>Bingfeng Zhang, Jimin Xiao, <strong>Jianbo Jiao</strong>, <a href="https://weiyc.github.io">Yunchao Wei</a>,<a href="https://scholar.google.com/citations?user=474TbQYAAAAJ&amp;hl=en">Yao Zhao</a></font><br>
<font size=2><em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> (<strong>T-PAMI</strong>), 2021</font><br>
<a href="pdfs/tpami21_2.pdf">[PDF]</a> <a href="bibs/tpami21_2.bib">[BibTeX]</a> <a href="https://github.com/zbf1991/A2GNN">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/tip21.png">
<strong>Multi-View Face Synthesis via Progressive Face Flow</strong><br>
<font size=2>Yangyang Xu, Xuemiao Xu, <strong>Jianbo Jiao</strong>, Keke Li, Cheng Xu, <a href="sf">Shengfeng He</a></font><br>
<font size=2><em>IEEE Transactions on Image Processing</em> (<strong>T-IP</strong>), 2021</font><br>
<a href="https://ieeexplore.ieee.org/document/9466401">[PDF]</a> <a href="bibs/tip21.bib">[BibTeX]</a> <a href="./">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:105px;margin:5px 5px" src="img/MICCAI20.png">
<strong>Self-Supervised Contrastive Video-Speech Representation Learning for Ultrasound</strong><br>
<font size=2><strong>Jianbo Jiao</strong>, Yifan Cai, Mohammad Alsharid, Lior Drukker, Aris Papageorghiou, <a href="http://www.ibme.ox.ac.uk/research/biomedia/people/professor-alison-noble">Alison Noble</a></font><br>
<font size=2><em>International Conference on Medical Image Computing and Computer Assisted Intervention</em> (<strong>MICCAI</strong>), <font color=#FF8080><strong>Oral Presentation (Early Acceptance)</strong></font>, 2020</font><br>
<a href="pdfs/MICCAI20.pdf">[PDF]</a> <a href="bibs/MICCAI20.bib">[BibTeX]</a> <a href="https://youtu.be/gpCc8IMF2NE">[Presentation Video]</a> <a href="pdfs/MICCAI20_GA.pdf">[Graphical Abstract]</a> [<a href="https://www.rsipvision.com/MICCAI2020-Wednesday/6/">MICCAI Daily Coverage</a>, <a href="https://www.rsipvision.com/ComputerVisionNews-2020December/30/">Best of MICCAI 2020 Coverage</a>]
<!-- <a href="./" title="to appear">[PDF]</a> <a href="./" title="to appear">[BibTeX]</a> -->
<br></p>

<p><img align="left" style="width:200px;height:105px;margin:5px 5px" src="img/ECCV_unisal.png">
<strong>Unified Image and Video Saliency Modeling</strong><br>
<font size=2><a href="https://rdroste.com">Richard Droste*</a>, <strong>Jianbo Jiao</strong>*, <a href="http://www.ibme.ox.ac.uk/research/biomedia/people/professor-alison-noble">Alison Noble</a> (*Equal contribution)</font><br>
<font size=2><em>European Conference on Computer Vision</em> (<strong>ECCV</strong>), <font color=#FF8080><strong>Spotlight Presentation</strong></font>, 2020</font><br>
<a href="pdfs/ECCV_unisal.pdf">[PDF]</a> <a href="bibs/ECCV_unisal.bib">[BibTeX]</a> <a href="https://www.youtube.com/watch?v=k6AX_7Blu_s&amp;t=3s">[Short Video]</a> <a href="https://www.youtube.com/watch?v=9pnxkgLrceo&amp;t=8s">[Long Video]</a> <a href="https://www.youtube.com/watch?v=4CqMPDI6BqE">[More Results]</a> <a href="https://github.com/rdroste/unisal">[Project]</a>
<!-- <a href="./" title="to appear">[PDF]</a> <a href="./" title="to appear">[BibTeX]</a> [[Project]](https://github.com/rdroste/unisal) -->
<br></p>

<p><img align="left" style="width:200px;height:105px;margin:5px 5px" src="img/ECCV_pace.png">
<strong>Self-Supervised Video Representation Learning by Pace Prediction</strong><br>
<font size=2>Jiangliu Wang, <strong>Jianbo Jiao</strong>, Yun-Hui Liu</font><br>
<font size=2><em>European Conference on Computer Vision</em> (<strong>ECCV</strong>), 2020</font><br>
<a href="pdfs/ECCV_pace.pdf">[PDF]</a> <a href="bibs/ECCV_pace.bib">[BibTeX]</a> <a href="https://www.youtube.com/watch?v=wYHteK4BHlk&amp;feature=youtu.be">[Short Video]</a> <a href="https://www.youtube.com/watch?v=LCeJYkSFXSk">[Long Video]</a> <a href="https://github.com/laura-wang/video-pace">[Code]</a>
<!-- <a href="./" title="to appear">[PDF]</a> <a href="./" title="to appear">[BibTeX]</a> <a href="./" title="to appear">[Code]</a> -->
<br></p>

<p><img align="left" style="width:200px;height:115px;margin:5px 5px" src="img/TMI20.png">
<strong>Self-Supervised Ultrasound to MRI Fetal Brain Image Synthesis</strong><br>
<font size=2><strong>Jianbo Jiao</strong>, <a href="http://www.ibme.ox.ac.uk/research/biomedia/people/ana-ineda-l-namburete">Ana Namburete</a>, Aris Papageorghiou, <a href="http://www.ibme.ox.ac.uk/research/biomedia/people/professor-alison-noble">Alison Noble</a></font><br>
<font size=2><em>IEEE Transactions on Medical Imaging</em> (<strong>T-MI</strong>), 2020</font><br>
<font size=2>This paper subsumes our <a href="pdfs/MICCAI_MLMI.pdf">preliminary work</a> presented at MICCAI-MLMI 2019.</font><br>
<a href="pdfs/TMI20.pdf">[PDF]</a> <a href="bibs/TMI20.bib">[BibTeX]</a> <a href="https://bitbucket.org/JianboJiao/ssus2mri/">[Code]</a>
<!-- <a href="./" title="to appear">[PDF]</a> <a href="./" title="to appear">[BibTeX]</a> <a href="./" title="to appear">[Code]</a> -->
<br></p>

<p><img align="left" style="width:200px;height:105px;margin:5px 5px" src="img/ISBI20.png">
<strong>Self-Supervised Representation Learning for Ultrasound Video</strong><br>
<font size=2><strong>Jianbo Jiao</strong>, <a href="https://rdroste.com">Richard Droste</a>, Lior Drukker, Aris Papageorghiou, <a href="http://www.ibme.ox.ac.uk/research/biomedia/people/professor-alison-noble">Alison Noble</a></font><br>
<font size=2><em>IEEE International Symposium on Biomedical Imaging</em> (<strong>ISBI</strong>), 2020</font><br>
<a href="pdfs/ISBI20.pdf">[PDF]</a> <a href="bibs/ISBI20.bib">[BibTeX]</a>
<br></p>

<p><img align="left" style="width:200px;height:105px;margin:5px 5px" src="img/ACMMM20.png">
<strong>Tactile Sketch Saliency</strong><br>
<font size=2><strong>Jianbo Jiao</strong>, <a href="http://www.ying-cao.com">Ying Cao</a>, <a href="https://sites.google.com/site/manfredlau/">Manfred Lau</a>, <a href="http://www.cs.cityu.edu.hk/~rynson/">Rynson W.H. Lau</a></font><br>
<font size=2><em>ACM International Conference on Multimedia</em> (<strong>ACM MM</strong>), 2020</font><br>
<a href="pdfs/ACMMM20.pdf">[PDF]</a> <a href="bibs/ACMMM20.bib">[BibTeX]</a> <a href="https://bitbucket.org/JianboJiao/tactilesketchsaliency">[Data &amp; Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:100px;margin:5px 5px" src="img/CVPR20.png">
<strong>Inferring Attention Shift Ranks of Objects for Image Saliency</strong><br>
<font size=2>Avishek Siris, <strong>Jianbo Jiao</strong>, Gary K.L. Tam, Xianghua Xie, <a href="http://www.cs.cityu.edu.hk/~rynson/">Rynson W.H. Lau</a></font><br>
<font size=2><em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<strong>CVPR</strong>), 2020</font><br>
<a href="pdfs/CVPR20.pdf">[PDF]</a> <a href="bibs/CVPR20.bib">[BibTeX]</a> <a href="https://www.youtube.com/watch?v=vj2bhD7ZgS0">[Presentation Video]</a> <a href="https://github.com/SirisAvishek/Attention_Shift_Ranks">[Project]</a> <a href="https://cove.thecvf.com/datasets/325">[Dataset]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/AAAI.png">
<strong>When AWGN-based Denoiser Meets Real Noises</strong><br>
<font size=2><a href="https://yzhouas.github.io">Yuqian Zhou</a>, <strong>Jianbo Jiao</strong>, <a href="https://brotherhuang.github.io">Haibin Huang</a>, Yang Wang, <a href="https://www.juew.org">Jue Wang</a>, <a href="https://www.humphreyshi.com/">Honghui Shi</a>, <a href="http://ifp-uiuc.github.io">Thomas S. Huang</a></font><br>
<font size=2><em>AAAI Conference on Artificial Intelligence</em> (<strong>AAAI</strong>), <font color=#FF8080><strong>Spotlight Presentation</strong></font>, 2020</font><br>
<a href="pdfs/AAAI.pdf">[PDF]</a> <a href="bibs/AAAI.bib">[BibTeX]</a> <a href="https://github.com/yzhouas/PD-Denoising-pytorch">[Code]</a> <a href="https://github.com/kritiksoman/GIMP-ML/wiki/References">[GIMP-ML]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/mlmi20.png">
<strong>Cross-Task Representation Learning for Anatomical Landmark Detection</strong><br>
<font size=2>Zeyu Fu, <strong>Jianbo Jiao</strong>, Michael Suttie, <a href="http://www.ibme.ox.ac.uk/research/biomedia/people/professor-alison-noble">Alison Noble</a></font><br>
<font size=2><em>International Conference on Medical Image Computing and Computer Assisted Intervention</em> (<strong>MICCAI</strong>) <em>Workshop on</em> <strong>MLMI</strong>, 2020</font><br>
<a href="https://arxiv.org/pdf/2009.13635.pdf">[PDF]</a> <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:N1DbM4_WBcsJ:scholar.google.com/&amp;output=citation&amp;scisdr=CgWeAti1EJHgneRHSNE:AAGBfm0AAAAAYBdCUNFJidXtSUun7s2q1iN6kYUFH5Id&amp;scisig=AAGBfm0AAAAAYBdCUOecB_CF0wBpm4uFHfNKxPqhoWid&amp;scisf=4&amp;ct=citation&amp;cd=-1&amp;hl=en">[BibTeX]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/pippi.png">
<strong>Differentiating Operator Skill During Routine Fetal Ultrasound Scanning Using Probe Motion Tracking</strong><br>
<font size=2>Yipei Wang, <a href="https://rdroste.com/">Richard Droste</a>, <strong>Jianbo Jiao</strong>, Harshita Sharma, Lior Drukker, Aris T. Papageorghiou, <a href="http://www.ibme.ox.ac.uk/research/biomedia/people/professor-alison-noble">Alison Noble</a></font><br>
<font size=2><em>International Conference on Medical Image Computing and Computer Assisted Intervention</em> (<strong>MICCAI</strong>) <em>Workshop on</em> <strong>ASMUS</strong>, <font color=#FF8080><strong>Oral Presentation</strong></font>, 2020</font><br>
<a href="https://link.springer.com/chapter/10.1007/978-3-030-60334-2_18">[PDF]</a> <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:B7bfC0Mlv6AJ:scholar.google.com/&amp;output=citation&amp;scisdr=CgWeAti1EJHgneRDLJU:AAGBfm0AAAAAYBdGNJVHpSOzvEC1Hk8y3_14FrtNquBY&amp;scisig=AAGBfm0AAAAAYBdGNGuOFlZ4GiHdQ9YOnZlnSWDInxcO&amp;scisf=4&amp;ct=citation&amp;cd=-1&amp;hl=en">[BibTeX]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/FormNet_TIP20.png">
<strong>FormNet: Formatted Learning for Image Restoration</strong><br>
<font size=2><strong>Jianbo Jiao</strong>, <a href="wc">Wei-Chih Tu</a>, <a href="https://scholar.google.com/citations?user=PGtHUI0AAAAJ&amp;hl=en">Ding Liu</a>, <a href="sf">Shengfeng He</a>,  <a href="rynson">Rynson Lau</a>, <a href="http://ifp-uiuc.github.io">Thomas S. Huang</a></font><br>
<font size=2><em>IEEE Transactions on Image Processing</em> (<strong>T-IP</strong>), 2020</font><br>
<font size=2>This paper subsumes our <a href="pdfs/cvprw.pdf">preliminary work</a> presented at CVPRW 2017.</font><br>
<a href="pdfs/tip_formnet.pdf">[PDF]</a> <a href="bibs/FormNet_TIP20.bib">[BibTeX]</a> <a href="https://bitbucket.org/JianboJiao/formnet">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/TIP20.png">
<strong>Connecting Image Denoising and High-Level Vision Tasks via Deep Learning</strong><br>
<font size=2><a href="https://scholar.google.com/citations?user=PGtHUI0AAAAJ&amp;hl=en">Ding Liu</a>, <a href="http://bihanwen.ece.illinois.edu">Bihan Wen</a>, <strong>Jianbo Jiao</strong>, <a href="https://scholar.google.com/citations?user=697UEEIAAAAJ&amp;hl=en">Xianming Liu</a>, <a href="https://www.atlaswang.com">Zhangyang Wang</a>, <a href="http://ifp-uiuc.github.io">Thomas S. Huang</a></font><br>
<font size=2><em>IEEE Transactions on Image Processing</em> (<strong>T-IP</strong>), 2020</font><br>
<a href="pdfs/tip_connecting.pdf">[PDF]</a> <a href="bibs/TIP20.bib">[BibTeX]</a> <a href="https://github.com/Ding-Liu/DeepDenoising">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:105px;margin:5px 5px" src="img/MICCAI_MLMI19.png">
<strong>Anatomy-Aware Self-Supervised Fetal MRI Synthesis from Unpaired Ultrasound Images</strong><br>
<font size=2><strong>Jianbo Jiao</strong>, <a href="http://www.ibme.ox.ac.uk/research/biomedia/people/ana-ineda-l-namburete">Ana Namburete</a>, Aris Papageorghiou, <a href="http://www.ibme.ox.ac.uk/research/biomedia/people/professor-alison-noble">Alison Noble</a></font><br>
<font size=2><em>International Conference on Medical Image Computing and Computer Assisted Intervention</em> (<strong>MICCAI</strong>) <em>Workshop on Machine Learning in Medical Imaging (<a href="http://mlmi2019.web.unc.edu">MLMI</a>)</em>, <font color=#FF8080><strong>Oral Presentation</strong></font>, 2019</font><br>
<a href="pdfs/MICCAI_MLMI.pdf">[PDF]</a> <a href="bibs/MICCAI_MLMI.bib">[BibTeX]</a> <a href="srcs/miccai_mlmi.ppsm">[Presentation]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/cvpr19.png">
<strong>Geometry-Aware Distillation for Indoor Semantic Segmentation</strong><br>
<font size=2><strong>Jianbo Jiao</strong>, <a href="https://weiyc.github.io">Yunchao Wei</a>, <a href="http://jiezequn.me">Zequn Jie</a>, <a href="https://www.humphreyshi.com/">Honghui Shi</a>, <a href="http://www.cs.cityu.edu.hk/~rynson/">Rynson W.H. Lau</a>, <a href="http://ifp-uiuc.github.io">Thomas S. Huang</a></font><br>
<font size=2><em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<strong>CVPR</strong>), 2019</font><br>
<a href="pdfs/cvpr_GAD.pdf">[PDF]</a> <a href="bibs/cvpr_GAD.bib">[BibTeX]</a> <a href="https://bitbucket.org/JianboJiao/semseggap/src/master/">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/cvpr19_2.png">
<strong>Self-Supervised Spatio-temporal Representation Learning for Videos by Predicting Motion and Appearance Statistics</strong><br>
<font size=2>Jiangliu Wang, <strong>Jianbo Jiao</strong>, <a href="https://sites.google.com/site/linchaobao/">Linchao Bao</a>, <a href="http://www.shengfenghe.com/">Shengfeng He</a>, Yunhui Liu, <a href="http://www.ee.columbia.edu/~wliu/">Wei Liu</a></font><br>
<font size=2><em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<strong>CVPR</strong>), 2019</font><br>
<!-- <a href="./" title="to appear">[PDF]</a> -->
<a href="pdfs/cvpr_VidMAS.pdf">[PDF]</a> <a href="bibs/cvpr_VidMAS.bib">[BibTeX]</a> <a href="https://github.com/laura-wang/video_repres_mas">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/ACMMM.png">
<strong>Ground-Aware Point Cloud Semantic Segmentation for Autonomous Driving</strong><br>
<font size=2>Jian Wu, <strong>Jianbo Jiao</strong>, <a href="https://sites.google.com/site/itrymanytimes/home">Qingxiong Yang</a>, Zheng-Jun Zha, <a href="http://staff.ustc.edu.cn/~xjchen99/">Xuejin Chen</a></font><br>
<font size=2><em>ACM International Conference on Multimedia</em> (<strong>ACM MM</strong>), <font color=#FF8080><strong>Oral Presentation</strong></font>, 2019</font><br>
<a href="pdfs/ACMMM.pdf">[PDF]</a> <a href="bibs/ACMMM.bib">[BibTeX]</a> <a href="http://www.moonx.ai/#/open">[Project]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/TCBB.png">
<strong>Few-shot Breast Cancer Metastases Classification via Unsupervised Cell Ranking</strong><br>
<font size=2>Jiaojiao Chen, <strong>Jianbo Jiao</strong>, <a href="http://www.shengfenghe.com/">Shengfeng He</a>, Guoqiang Han, <a href="https://sn.polyu.edu.hk/en/people/academic_staff/index.html#harry.qin">Jing Qin</a></font><br>
<font size=2><em>IEEE Transactions on Computational Biology and Bioinformatics</em> (<strong>T-CBB</strong>), 2019</font><br>
<a href="pdfs/TCBB.pdf">[PDF]</a> <a href="bibs/TCBB.bib">[BibTeX]</a> <a href="https://github.com/jiaojiao-Chen/fewshot-camelyon">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/TIP.png">
<strong>Stereoscopic Image Generation from Light Field with Disparity Scaling and Super-Resolution</strong><br>
<font size=2>Tao Yan, <strong>Jianbo Jiao</strong>, Wenxi Liu, <a href="http://www.cs.cityu.edu.hk/~rynson/">Rynson W.H. Lau</a></font><br>
<font size=2><em>IEEE Transactions on Image Processing</em> (<strong>T-IP</strong>), 2019</font><br>
<a href="pdfs/TIP.pdf">[PDF]</a> <a href="bibs/TIP.bib">[BibTeX]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/TMM.png">
<strong>Referring Image Segmentation by Generative Adversarial Learning</strong><br>
<font size=2>Shuang Qiu, <a href="https://scholar.google.com/citations?user=474TbQYAAAAJ&amp;hl=en">Yao Zhao</a>, <strong>Jianbo Jiao</strong>, <a href="https://weiyc.github.io">Yunchao Wei</a>, Shikui Wei</font><br>
<font size=2><em>IEEE Transactions on Multimedia</em> (<strong>T-MM</strong>), 2019</font><br>
<a href="pdfs/TMM.pdf">[PDF]</a> <a href="bibs/TMM.bib">[BibTeX]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/eccv.png">
<strong>Look Deeper into Depth: Monocular Depth Estimation with Semantic Booster and Attention-Driven Loss</strong><br>
<font size=2><strong>Jianbo Jiao</strong>, <a href="http://www.ying-cao.com">Ying Cao</a>, <a href="https://ybsong00.github.io">Yibing Song</a>, <a href="http://www.cs.cityu.edu.hk/~rynson/">Rynson W.H. Lau</a></font><br>
<font size=2><em>European Conference on Computer Vision</em> (<strong>ECCV</strong>), 2018</font><br>
<a href="pdfs/eccv_LDiD.pdf">[PDF]</a> <a href="bibs/eccv_LDiD.bib">[BibTeX]</a> <a href="https://bitbucket.org/JianboJiao/ldid/src/master/">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:105px;margin:5px 5px" src="img/eccv_web.png">
<strong>Task-Driven Webpage Saliency</strong><br>
<font size=2><a href="https://quanlzheng.github.io">Quanlong Zheng</a>, <strong>Jianbo Jiao</strong>, <a href="http://www.ying-cao.com">Ying Cao</a>, <a href="http://www.cs.cityu.edu.hk/~rynson/">Rynson W.H. Lau</a></font><br>
<font size=2><em>European Conference on Computer Vision</em> (<strong>ECCV</strong>), 2018</font><br>
<a href="pdfs/eccv_TDSal.pdf">[PDF]</a> <a href="bibs/eccv_TDSal.bib">[BibTeX]</a> <a href="https://quanlzheng.github.io/projects/Task-driven-Webpage-Saliency.html">[Project]</a>
<br></p>

<p><img align="left" style="width:200px;height:105px;margin:5px 5px" src="img/iccv.png">
<strong>Delving into Salient Object Subitizing and Detection</strong><br>
<font size=2><a href="http://www.shengfenghe.com/">Shengfeng He</a>, <strong>Jianbo Jiao</strong>, Xiaodan Zhang, <a href="http://cs.scut.edu.cn/jxgl/yjsjy/dsjj/bshshdsh/17gh4u6trjjd6.xhtml">Guoqiang Han</a>, <a href="http://www.cs.cityu.edu.hk/~rynson/">Rynson W.H. Lau</a></font><br>
<font size=2><em>IEEE International Conference on Computer Vision</em> (<strong>ICCV</strong>), 2017</font><br>
<a href="pdfs/iccv.pdf">[PDF]</a> <a href="bibs/iccv.bib">[BibTeX]</a></p>

<p><img align="left" style="width:200px;height:105px;margin:5px 5px" src="img/ijcv.png">
<strong>Joint Image Denoising and Disparity Estimation via Stereo Structure PCA and Noise-Tolerant Cost</strong><br>
<font size=2><strong>Jianbo Jiao</strong>, <a href="https://sites.google.com/site/itrymanytimes/home">Qingxiong Yang</a>, <a href="http://www.shengfenghe.com/">Shengfeng He</a>, <a href="https://sites.google.com/site/shuhanggu/home">Shuhang Gu</a>, <a href="http://www4.comp.polyu.edu.hk/~cslzhang/">Lei Zhang</a>, <a href="http://www.cs.cityu.edu.hk/~rynson/">Rynson W. H. Lau</a></font><br>
<font size=2><em>International Journal of Computer Vision</em> (<strong>IJCV</strong>), 2017</font><br>
<a href="pdfs/ijcv.pdf">[PDF]</a> <a href="bibs/ijcv.bib">[BibTeX]</a> <a href="https://bitbucket.org/JianboJiao/jointstereodn/src/master/">[Code]</a> <a href="https://drive.google.com/file/d/1yjQs_fH7SQ-7pSLigklUkNH96SovghWG/view?usp=sharing">[Data]</a></p>

<p><img align="left" img style="width:200px;height:105px;margin:5px 5px" src="img/cvprw.png">
<strong>FormResNet: Formatted Residual Learning for Image Restoration</strong><br>
<font size=2><strong>Jianbo Jiao</strong>, <a href="https://sites.google.com/site/wctu1009/">Wei-Chih Tu</a>, <a href="http://www.shengfenghe.com/">Shengfeng He</a>, <a href="http://www.cs.cityu.edu.hk/~rynson/">Rynson W. H. Lau</a></font><br>
<font size=2><em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<strong>CVPR</strong>) <em>Workshop (<a href="http://www.vision.ee.ethz.ch/ntire17/">NTIRE</a>)</em>, <font color=#FF8080><strong>Oral Presentation</strong></font>, 2017</font><br>
<a href="pdfs/cvprw.pdf">[PDF]</a> <a href="bibs/cvprw.bib">[BibTeX]</a> <a href="https://bitbucket.org/JianboJiao/formresnet/src/master/">[Code]</a> <a href="srcs/cvprw_slid.ppsm">[Slides]</a> <a href="srcs/cvprw_pos.pdf">[Poster]</a></p>

<p><img align="left" style="width:200px;height:105px;margin:5px 5px" src="img/icip.png">
<strong>A Hand Pose Tracking Benchmark From Stereo Matching</strong><br>
<font size=2><a href="https://sites.google.com/site/zhjw1988/">Jiawei Zhang</a>, <strong>Jianbo Jiao</strong>, <a href="http://www.cs.cityu.edu.hk/~mlchen2/">Mingliang Chen</a>, <a href="http://vision.sia.cn/our%20team/QuLiangqun-homepage/vision-Quliangqiong(English).html">Liangqiong Qu</a>, <a href="http://www.cs.cityu.edu.hk/~xiaobinxu2/">Xiaobin Xu</a>, <a href="https://sites.google.com/site/itrymanytimes/home">Qingxiong Yang</a></font><br>
<font size=2><em>IEEE International Conference on Image Processing</em> (<strong>ICIP</strong>), <font color=#FF8080><strong>Oral Presentation</strong></font>, 2017</font><br>
<a href="pdfs/icip.pdf">[PDF]</a> <a href="https://arxiv.org/pdf/1610.07214.pdf">[Tech Report]</a> <a href="bibs/icip.bib">[BibTeX]</a> [<a href="https://github.com/zhjwustc/icip17_stereo_hand_pose_dataset">Data</a>: <a href="https://www.dropbox.com/sh/g13petlurikkivo/AACgwsoKsbtzMxX_e6bhH39Qa?dl=0">Dropbox</a>, <a href="https://www.google.com/url?q=https%3A%2F%2Fportland-my.sharepoint.com%2F%3Af%3A%2Fg%2Fpersonal%2Fjiawzhang8-c_my_cityu_edu_hk%2FEkznohE3YL1Jk8igTCQ4HqYBg_9WJi9hWAetybea9o3iMQ%3Fe%3DkcbMmj&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNGxPD4n-BZYzVcEQ0mmFIwFCz7DaQ">OneDrive</a>]</p>

<p><img align="left" style="width:200px;height:105px;margin:5px 5px" src="img/tcsvt.png">
<strong>Color Image Guided Boundary-inconsistent Region Refinement for Stereo Matching</strong><br>
<font size=2><strong>Jianbo Jiao</strong>, <a href="http://www.ece.pku.edu.cn/index.php?a=show&amp;catid=507&amp;id=48">Ronggang Wang</a>, <a href="http://www.ece.pku.edu.cn/index.php?a=show&amp;catid=507&amp;id=42">Wenmin Wang</a>, <a href="https://www.researchgate.net/profile/Dagang_Li">Dagang Li</a>, <a href="http://www.jdl.ac.cn/htm-gaowen/">Wen Gao</a></font><br>
<font size=2><em>IEEE Transactions on Circuits and Systems for Video Technology</em> (<strong>T-CSVT</strong>), 2015</font><br>
<a href="pdfs/tcsvt.pdf">[PDF]</a> <a href="bibs/tcsvt.bib">[BibTeX]</a> <a href="https://bitbucket.org/JianboJiao/disprefine/src/master/">[Code]</a></p>

<p><img align="left" style="width:200px;height:105px;margin:5px 5px" src="img/mm.png">
<strong>Local Stereo Matching with Improved Matching Cost and Disparity Refinement</strong><br>
<font size=2><strong>Jianbo Jiao</strong>, <a href="http://www.ece.pku.edu.cn/index.php?a=show&amp;catid=507&amp;id=48">Ronggang Wang</a>, <a href="http://www.ece.pku.edu.cn/index.php?a=show&amp;catid=507&amp;id=42">Wenmin Wang</a>, <a href="https://www.researchgate.net/profile/Shengfu_Dong">Shengfu Dong</a>, <a href="https://www.researchgate.net/profile/Zhenyu_Wang38">Zhenyu Wang</a>, <a href="http://www.jdl.ac.cn/htm-gaowen/">Wen Gao</a></font><br>
<font size=2><em>IEEE Multimedia</em>, 2014</font><br>
<a href="pdfs/mm.pdf">[PDF]</a> <a href="bibs/MM.bib">[BibTeX]</a></p>

<p><img align="left" style="width:200px;height:105px;margin:5px 5px" src="img/icme.png">
<strong>Cost-Volume Filtering-Based Stereo Matching with Improved Matching Cost and Secondary Refinement</strong><br>
<font size=2><strong>Jianbo Jiao</strong>, <a href="http://www.ece.pku.edu.cn/index.php?a=show&amp;catid=507&amp;id=48">Ronggang Wang</a>, <a href="http://www.ece.pku.edu.cn/index.php?a=show&amp;catid=507&amp;id=42">Wenmin Wang</a>, <a href="https://www.researchgate.net/profile/Shengfu_Dong">Shengfu Dong</a>, <a href="https://www.researchgate.net/profile/Zhenyu_Wang38">Zhenyu Wang</a>, <a href="http://www.jdl.ac.cn/htm-gaowen/">Wen Gao</a></font><br>
<font size=2><em>IEEE International Conference on Multimedia and Expo</em> (<strong>ICME</strong>), <font color=#FF8080><strong>Oral Presentation</strong></font> (<font color="red"><strong>Best Student Paper</strong></font> candidate), 2014</font><br>
<a href="pdfs/icme.pdf">[PDF]</a> <a href="bibs/icme.bib">[BibTeX]</a> <a href="srcs/icme_slid.ppsm">[Slides]</a> <a href="srcs/icme_pos.pdf">[Poster]</a> <a href="https://youtu.be/w6jJu3GXPVY">[demo]</a></p>

					</section>

			

      <div class="footer">
	<hr class="thin" />
	<div class="pure-menu pure-menu-horizontal pure-menu-open">
		<ul class="footer-menu">
		
			
			<li><a href="/"><i class="fa fa-home" aria-hidden="true"></i></a></li>
		
		</ul>
	</div>

	
	<p>&copy; 2024, JianboJiao. All rights reserved. </p>
	<p>Credits <a href="https://github.com/tmaiaroto/hugo-redlounge" target="_blank">Red Lounge</a> and <a href="https://gohugo.io" target="_blank">Hugo</a>.</p>
</div>

    </div>
  </div>
	

	

  
</body>
</html>
