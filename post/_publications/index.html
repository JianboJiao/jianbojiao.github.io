<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
  <title>
    Publications // Jianbo Jiao
  </title>

  <link href="http://gmpg.org/xfn/11" rel="profile">
<meta http-equiv="content-type" content="text/html; charset=utf-8">


<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

<meta name="description" content="">
<meta name="keywords" content="">
<meta name="author" content="">
<meta name="generator" content="Hugo 0.49" />

  <meta property="og:title" content="Publications" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:locale" content="en_US" />
<meta property="og:url" content="https://jianbojiao.github.io/post/_publications/" />


  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.5.0/base-min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.5.0/pure-min.css">
  
  
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pure/0.5.0/grids-responsive-min.css">
  
  

  <link rel="stylesheet" href="https://jianbojiao.github.io//css/redlounge.css">
  <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet">
  <link rel="stylesheet" href="https://jianbojiao.github.io//css/academicons.min.css">
  <link href='//fonts.googleapis.com/css?family=Raleway:400,200,100,700,300,500,600,800' rel='stylesheet' type='text/css'>
  <link href='//fonts.googleapis.com/css?family=Libre+Baskerville:400,700,400italic' rel='stylesheet' type='text/css'>

  
  
  

  <link rel="apple-touch-icon-precomposed" sizes="104x144" href="big.png">
  <link rel="shortcut icon" type="image/x-icon" href="small3.png">

  
  <link href="" rel="alternate" type="application/rss+xml" title="Jianbo Jiao" />

    
  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.7/styles/tomorrow-night-bright.min.css">
  
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.7/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>


  

  

  

  
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', "UA-102110812-1", 'auto');
  ga('send', 'pageview');
</script>

</head>

<body>
	

	<div id="layout" class="pure-g">
    <div class="sidebar pure-u-1 pure-u-md-1-4">
  <div class="header">
    

	

    <h1 class="brand-title">Jianbo Jiao</h1>
    <h2 class="brand-tagline">Fellow of the HEA</h2>
    <h2 class="brand-tagline">Associate Professor</h2>
    
    <h2 class="brand-tagline">School of Computer Science</h2>
    <h2 class="brand-tagline">University of Birmingham</h2>

    <nav class="nav">
      <ul class="nav-list">
        <li class="nav-item"><span class="nav-item-separator">//</span><a href="https://jianbojiao.github.io/">Home</a></li>
        
          <li class="nav-item"><span class="nav-item-separator">//</span><a href="https://scholar.google.com/citations?user=HkEiMMwAAAAJ&amp;hl=en">Google Scholar</a></li>
        
          <li class="nav-item"><span class="nav-item-separator">//</span><a href="https://mix.jianbojiao.com/">Group</a></li>
        
          <li class="nav-item"><span class="nav-item-separator">//</span><a href="https://www.linkedin.com/in/JianboJiao/">LinkedIn</a></li>
        
          <li class="nav-item"><span class="nav-item-separator">//</span><a href="mailto:j.jiao@bham.ac.uk%20or%20jiaojianbo.i@gmail.com">Email</a></li>
        
          <li class="nav-item"><span class="nav-item-separator">//</span><a href="misc_index.html">Misc</a></li>
        
      </ul>
    </nav>

    

  </div>
</div>


	

    <div class="content pure-u-1 pure-u-md-3-4">
		<a name="top"></a>
		

		
			
	    
  		<section class="post">
            <h1 class="post-title">Publications</h1>
						

            <p><br></p>

<p><img align="left" style="width:200px;height:120px;margin:5px 5px" src="img/bmvc25_visualsplit.png">
<strong>Exploring Image Representation with Decoupled Classical Visual Descriptors</strong><br>
<font size=2> Chenyuan Qu, Hao Chen, <strong>Jianbo Jiao</strong></font><br>
<font size=2><em>British Machine Vision Conference</em> (<strong>BMVC</strong>), 2025</font><br>
<a href="https://openreview.net/pdf?id=VQy7PNQE2l">[PDF]</a> <a href="bibs/bmvc25_visualsplit.bib">[BibTeX]</a> <a href="./">[arXiv]</a> <a href="./">[Short Video Intro]</a> <a href="https://chenyuanqu.com/VisualSplit/">[Project Page]</a>
<br></p>

<p><img align="left" style="width:200px;height:120px;margin:5px 5px" src="img/bmvc25_harry.png">
<strong><i>What Can We Learn from Harry Potter?</i><br>
An Exploratory Study of Visual Representation Learning from Atypical Videos</strong><br>
<font size=2> Qiyue Sun, Qiming Huang, Yang Yang, Hongjun Wang, <strong>Jianbo Jiao</strong></font><br>
<font size=2><em>British Machine Vision Conference</em> (<strong>BMVC</strong>), 2025</font><br>
<a href="https://openreview.net/pdf?id=jWQWQuzduK">[PDF]</a> <a href="bibs/bmvc25_harry.bib">[BibTeX]</a> <a href="./">[arXiv]</a> <a href="https://youtu.be/-AMkMvN1mMM">[Short Video Intro]</a> <a href="https://julysun98.github.io/atypical_dataset/">[Project Page]</a>
<br></p>

<p><img align="left" style="width:200px;height:120px;margin:5px 5px" src="img/bmvc25_abs.png">
<strong>An Explorative Study on Abstract Images and Visual Representations Learned from Them</strong><br>
<font size=2> Haotian Li, <strong>Jianbo Jiao</strong></font><br>
<font size=2><em>British Machine Vision Conference</em> (<strong>BMVC</strong>), 2025</font><br>
<a href="https://openreview.net/pdf?id=b3sQnyQbgz">[PDF]</a> <a href="bibs/bmvc25_abs.bib">[BibTeX]</a> <a href="./">[arXiv]</a> <a href="./">[Short Video Intro]</a> <a href="https://fronik-lihaotian.github.io/HAID_page/">[Project Page]</a> <a href="https://huggingface.co/datasets/Froink/HAID_zipped">[Dataset]</a>
<br></p>

<p><img align="left" style="width:200px;height:120px;margin:5px 5px" src="img/bmvc25_avs.png">
<strong>Audio-Visual Separation with Hierarchical Fusion and Representation Alignment</strong><br>
<font size=2> Han Hu<em>, Dongheng Lin</em>, Qiming Huang, Yuqi Hou, Hyung Jin Chang, <strong>Jianbo Jiao</strong></font><br>
<font size=2><em>British Machine Vision Conference</em> (<strong>BMVC</strong>), 2025</font><br>
<a href="https://openreview.net/pdf?id=lFzBY8w4y7">[PDF]</a> <a href="bibs/bmvc25_avs.bib">[BibTeX]</a> <a href="./">[arXiv]</a> <a href="./">[Short Video Intro]</a> <a href="https://happy-new-bears.github.io/hfra-audiosep/">[Project Page]</a>
<br></p>

<p><img align="left" style="width:200px;height:120px;margin:5px 5px" src="img/bmvc25_hate.png">
<strong>Multimodal Hate Detection Using Dual-Stream Graph Neural Networks</strong><br>
<font size=2> Jiangbei Yue, Shuonan Yang, Tailin Chen, <strong>Jianbo Jiao</strong>, Zeyu Fu</font><br>
<font size=2><em>British Machine Vision Conference</em> (<strong>BMVC</strong>), 2025</font><br>
<a href="https://openreview.net/pdf?id=uHwQgPu43j">[PDF]</a> <a href="bibs/bmvc25_hate.bib">[BibTeX]</a> <a href="./">[Project Page]</a>
<br></p>

<p><img align="left" style="width:200px;height:120px;margin:5px 5px" src="img/iccv25.png">
<strong>LocalDyGS: Multi-view Global Dynamic Scene Modeling via Adaptive Local Implicit Feature Decoupling</strong><br>
<font size=2>  Jiahao Wu, Rui Peng, <strong>Jianbo Jiao</strong>, Jiayu Yang, Luyang Tang, Kaiqiang Xiong, Jie Liang, Jinbo Yan, Runling Liu, Ronggang Wang</font><br>
<font size=2><em>IEEE/CVF International Conference on Computer Vision</em> (<strong>ICCV</strong>), 2025</font><br>
<a href="https://arxiv.org/pdf/2507.02363">[PDF]</a> <a href="bibs/iccv25.bib">[BibTeX]</a> <a href="https://arxiv.org/abs/2507.02363">[arXiv]</a> <a href="https://wujh2001.github.io/LocalDyGS/">[Project Page]</a> <a href="https://huggingface.co/datasets/BestWJH/VRU_Basketball/tree/main">[Dataset]</a>
<br></p>

<p><img align="left" style="width:200px;height:120px;margin:5px 5px" src="img/acmmm25.jpg">
<strong>DeHate: A Holistic Hateful Video Dataset for Explicit and Implicit Hate Detection</strong><br>
<font size=2> Yuchen Zhang, Tailin Chen, Jiangbei Yue, Yueming Sun, Rahul Singh, <strong>Jianbo Jiao</strong>, Zeyu Fu</font><br>
<font size=2><em>ACM Multimedia 2025 Dataset Track</em> (<strong>ACMMM Datasets</strong>), 2025</font><br>
<a href="https://openreview.net/pdf?id=D4GxwGy41E">[PDF]</a> <a href="bibs/acm25.bib">[BibTeX]</a> <a href="https://github.com/yuchen-zhang-essex/DeHate">[Dataset]</a>
<br></p>

<p><img align="left" style="width:200px;height:120px;margin:5px 5px" src="img/iclr25.gif">
<strong>Revisit the Open Nature of Open Vocabulary Semantic Segmentation</strong><br>
<font size=2> Qiming Huang, Han Hu, <strong>Jianbo Jiao</strong></font><br>
<font size=2><em>International Conference on Learning Representations</em> (<strong>ICLR</strong>), 2025</font><br>
<a href="https://openreview.net/pdf?id=2vHIHrJAcI">[PDF]</a> <a href="bibs/iclr25.bib">[BibTeX]</a> <a href="./">[arXiv]</a> <a href="https://www.youtube.com/watch?v=wP9RWue5D1I">[Short Video Intro]</a> <a href="https://qiming-huang.github.io/RevisitOVS/">[Project Page and code]</a>
<br></p>

<p><img align="left" style="width:200px;height:120px;margin:5px 5px" src="img/cvpr25.png">
<strong>CoMBO: Conflict Mitigation via Branched Optimization for Class Incremental Segmentation</strong><br>
<font size=2> Kai Fang, Anqi Zhang, Guangyu Gao, <strong>Jianbo Jiao</strong>, Chi Harold Liu, Yunchao Wei</font><br>
<font size=2><em>IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> (<strong>CVPR</strong>), 2025</font><br>
<a href="https://guangyu-ryan.github.io/CVPR2025_CISS.pdf">[PDF]</a> <a href="bibs/cvpr25.bib">[BibTeX]</a> <a href="https://arxiv.org/abs/2504.04156">[arXiv]</a> <a href="https://guangyu-ryan.github.io/CoMBO">[Project Page and code]</a>
<br></p>

<p><img align="left" style="width:200px;height:120px;margin:5px 5px" src="img/physchem25.png">
<strong>Transformer-Based Models for Predicting Molecular Structures from Infrared Spectra Using Patch-Based Self-Attention</strong><br>
<font size=2> Wenjin Wu, Aleš Leonardis, <strong>Jianbo Jiao</strong>, Jun Jiang, Linjiang Chen</font><br>
<font size=2><em>The Journal of Physical Chemistry A</em>, 2025</font><br>
<a href="https://pubs.acs.org/doi/10.1021/acs.jpca.4c05665">[Paper]</a> <a href="bibs/physchem25.bib">[BibTeX]</a> <a href="./">[arXiv]</a> <a href="https://wenjin886.github.io/PatchBasedSelfAttention/">[Project Page and code]</a>
<br></p>

<p><img align="left" style="width:200px;height:120px;margin:5px 5px" src="img/prformer.png">
<strong>PRFormer: Matching Proposal and Reference Masks by Semantic and Spatial Similarity for Few-Shot Semantic Segmentation</strong><br>
<font size=2> Guangyu Gao, Anqi Zhang, <strong>Jianbo Jiao</strong>, Chi Harold Liu, Yunchao Wei</font><br>
<font size=2><em>IEEE Transactions on Circuits and Systems for Video Technology</em> (<strong>T-CSVT</strong>), 2025</font><br>
<a href="pdfs/prformer.pdf">[PDF]</a> <a href="bibs/prformer.bib">[BibTeX]</a> <a href="https://github.com/ANDYZAQ/PRFormer">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:120px;margin:5px 5px" src="img/cvpr24x360.png">
<strong>360+x: A Panoptic Multi-modal Scene Understanding Dataset</strong><br>
<font size=2> Hao Chen, Yuqi Hou, Chenyuan Qu, Irene Testini, Xiaohan Hong, <strong>Jianbo Jiao</strong></font><br>
<font size=2><em>IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> (<strong>CVPR</strong>), <font color=#FF8080><strong>Oral Presentation (3.3% of accepted papers)</strong></font>, 2024</font><br>
<a href="pdfs/cvpr24x360.pdf">[PDF]</a> <a href="bibs/cvpr24x360.bib">[BibTeX]</a> <a href="https://arxiv.org/abs/2404.00989">[arXiv]</a> <a href="https://x360dataset.github.io/">[Project Page]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/scirep.png">
<strong>Show from Tell: Audio-Visual Modelling in a Clinical Setting</strong><br>
<font size=2><strong>Jianbo Jiao</strong>*, Mohammad Alsharid*, Lior Drukker, Aris T. Papageorghiou, <a href="https://www.robots.ox.ac.uk/~az/">Andrew Zisserman</a>, <a href="http://www.ibme.ox.ac.uk/research/biomedia/people/professor-alison-noble">Alison Noble</a></font><br>
<font size=2><em>Scientific Reports</em>, 2024</font><br>
<a href="https://rdcu.be/dNcmb">[PDF]</a> <a href="bibs/scirep.bib">[BibTeX]</a> <a href="https://www.nature.com/articles/s41598-024-66160-4?_gl=1*12hjhqt*_up*MQ..&amp;gclid=Cj0KCQjwv7O0BhDwARIsAC0sjWPiDFyuf4Hk8_rh8qOZarMZVbPYc-mDy31djVkhEAP_uI6RjKWLt20aAnhCEALw_wcB">[Online Article]</a>
<br></p>

<p><img align="left" style="width:200px;height:120px;margin:5px 5px" src="img/micad24.png">
<strong>Out-of-Clinical-Distribution Detection with a Softmax-Conditioned Variational Autoencoder Regulariser: Application to Fetal Ultrasound</strong><br>
<font size=2> Kangning Zhang, <strong>Jianbo Jiao</strong>, <a href="http://www.ibme.ox.ac.uk/research/biomedia/people/professor-alison-noble">Alison Noble</a></font><br>
<font size=2><em>International Conference on Medical Imaging and Computer-Aided Diagnosis</em> (<strong>MICAD</strong>), <font color=#FF8080><strong>Oral Presentation</strong></font>, <i class="fas fa-trophy"></i><font color="e63946"><strong>Best Paper Award</strong></font>, 2024</font><br>
<a href="pdfs/micad24.pdf">[PDF]</a> <a href="bibs/micad24.bib">[BibTeX]</a> <a href="https://github.com/kangning-zhang/OOD">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:120px;margin:5px 5px" src="img/accv24.png">
<strong>Few Exemplar-Based General Medical Image Segmentation via Domain-Aware Selective Adaptation</strong><br>
<font size=2> Chen Xu*, Qiming Huang*, Yuqi Hou, Jiangxing Wu, Fan Zhang, Hyung Jin Chang, <strong>Jianbo Jiao</strong></font><br>
<font size=2><em>Asian Conference on Computer Vision</em> (<strong>ACCV</strong>), 2024</font><br>
<a href="https://xuchenjune.github.io/FEMed/FEMedSegment.pdf">[PDF]</a> <a href="bibs/accv24.bib">[BibTeX]</a> <a href="https://arxiv.org/abs/2410.09254">[arXiv]</a> <a href="https://xuchenjune.github.io/FEMed/">[Project and code]</a>
<br></p>

<p><img align="left" style="width:200px;height:120px;margin:5px 5px" src="img/neurips24_bridge.png">
<strong>Bridge the Points: Graph-based Few-shot Segment Anything Semantically</strong><br>
<font size=2> Anqi Zhang, Guangyu Gao, <strong>Jianbo Jiao</strong>, Chi Harold Liu, Yunchao Wei</font><br>
<font size=2><em>Annual Conference on Neural Information Processing Systems</em> (<strong>NeurIPS</strong>), <font color=#FF8080><strong>Spotlight Presentation</strong></font>, 2024</font><br>
<a href="https://arxiv.org/pdf/2410.06964">[PDF]</a> <a href="bibs/neurips24_bridge.bib">[BibTeX]</a> <a href="https://arxiv.org/abs/2410.06964">[arXiv]</a> <a href="https://andyzaq.github.io/GF-SAM/">[Project Page]</a>
<br></p>

<p><img align="left" style="width:200px;height:120px;margin:5px 5px" src="img/neurips24_scgs.png">
<strong>Structure Consistent Gaussian Splatting with Matching Prior for Few-shot Novel View Synthesis</strong><br>
<font size=2> Rui Peng, Wangze Xu, Luyang Tang, Liwei Liao, <strong>Jianbo Jiao</strong>, Ronggang Wang</font><br>
<font size=2><em>Annual Conference on Neural Information Processing Systems</em> (<strong>NeurIPS</strong>), 2024</font><br>
<a href="https://arxiv.org/pdf/2411.03637">[PDF]</a> <a href="bibs/neurips24_scgs.bib">[BibTeX]</a> <a href="https://arxiv.org/abs/2411.03637">[arXiv]</a> <a href="https://github.com/prstrive/SCGaussian">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:120px;margin:5px 5px" src="img/eccv24_DiGARR.png">
<strong>Disentangled Generation and Aggregation for Robust Radiance Fields</strong><br>
<font size=2> Shihe Shen*, Huachen Gao*, Wangze Xu, Rui Peng, Luyang Tang, Kaiqiang Xiong, <strong>Jianbo Jiao</strong>, Ronggang Wang</font><br>
<font size=2><em>European Conference on Computer Vision</em> (<strong>ECCV</strong>), 2024</font><br>
<a href="https://arxiv.org/pdf/2409.15715">[PDF]</a> <a href="bibs/eccv24_DiGARR.bib">[BibTeX]</a> <a href="https://arxiv.org/abs/2409.15715">[arXiv]</a> <a href="https://github.com/GaoHchen/DiGARR">[Code]</a> <a href="https://gaohchen.github.io/DiGARR/">[Project Page]</a>
<br></p>

<p><img align="left" style="width:200px;height:120px;margin:5px 5px" src="img/eccv24_mvpgs.png">
<strong>MVPGS: Excavating Multi-view Prior for Gaussian Splatting from Sparse Input Views</strong><br>
<font size=2> Wangze Xu, Huachen Gao, Shihe Shen, Rui Peng, <strong>Jianbo Jiao</strong>, Ronggang Wang</font><br>
<font size=2><em>European Conference on Computer Vision</em> (<strong>ECCV</strong>), 2024</font><br>
<a href="https://arxiv.org/pdf/2409.14316">[PDF]</a> <a href="bibs/eccv24_mvpgs.bib">[BibTeX]</a> <a href="https://arxiv.org/abs/2409.14316">[arXiv]</a> <a href="https://github.com/zezeaaa/MVPGS">[Code]</a> <a href="https://zezeaaa.github.io/projects/MVPGS/">[Project Page]</a>
<br></p>

<p><img align="left" style="width:200px;height:120px;margin:5px 5px" src="img/eccv24_surf.png">
<strong>Surface-Centric Modeling for High-Fidelity Generalizable Neural Surface Reconstruction</strong><br>
<font size=2> Rui Peng, Shihe Shen, Kaiqiang Xiong, Huachen Gao, <strong>Jianbo Jiao</strong>, Xiaodong Gu, Ronggang Wang</font><br>
<font size=2><em>European Conference on Computer Vision</em> (<strong>ECCV</strong>), 2024</font><br>
<a href="https://arxiv.org/pdf/2409.03634">[PDF]</a> <a href="bibs/eccv24_surf.bib">[BibTeX]</a> <a href="https://arxiv.org/abs/2409.03634">[arXiv]</a> <a href="https://github.com/prstrive/SuRF">[Code]</a>
<br></p>

<p><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
<img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/asmus24.png">
<strong>Fetal Ultrasound Video Representation Learning using Contrastive Rubik’s Cube Recovery</strong><br>
<font size=2>Kangning Zhang, <strong>Jianbo Jiao</strong>, <a href="http://www.ibme.ox.ac.uk/research/biomedia/people/professor-alison-noble">Alison Noble</a></font><br>
<font size=2><em>International Conference on Medical Image Computing and Computer Assisted Intervention Workshop</em> (<a href="https://miccai-ultrasound.github.io/#/asmus24"><strong>MICCAI ASMUS</strong></a>), <font color=#FF8080><strong>Oral Presentation</strong></font>, [<i class="fas fa-trophy"></i><a href="img/MICCAI24_ASMUS_BestPaperAward.png"><font color="e63946"><strong>Best Paper Award</strong></font></a> and <i class="fas fa-trophy"></i><a href="img/MICCAI24_ASMUS_BestPresentationrunner-up.png"><font color="e63946"><strong>Best Presentation (Runner-Up) Award</strong></font></a>], 2024</font><br>
<a href="pdfs/asmus24.pdf">[PDF]</a> <a href="bibs/asmus24.bib">[BibTeX]</a> <a href="https://github.com/kangning-zhang/CRCR">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:120px;margin:5px 5px" src="img/cvpr24dymvhumans.png">
<strong>DyMVHumans: A Multi-View Video Benchmark for High-Fidelity Dynamic Human Modeling</strong><br>
<font size=2> Xiaoyun Zheng, Liwei Liao, Xufeng Li, <strong>Jianbo Jiao</strong>, Rongjie Wang, Feng Gao, Shiqi Wang, Ronggang Wang</font><br>
<font size=2><em>IEEE/CVF Conference on Computer Vision and Pattern Recognition</em> (<strong>CVPR</strong>), 2024</font><br>
<a href="pdfs/cvpr24dymvhumans.pdf">[PDF]</a> <a href="bibs/cvpr24dymvhumans.bib">[BibTeX]</a> <a href="https://arxiv.org/abs/2403.16080">[arXiv]</a> <a href="https://pku-dymvhumans.github.io/">[Project Page]</a>
<br></p>

<p><img align="left" style="width:200px;height:120px;margin:5px 5px" src="img/wacv24dpt.jpg">
<strong>Disentangled Pre-training for Image Matting</strong><br>
<font size=2>Yanda Li, Zilong Huang, Gang Yu, Ling Chen, <a href="https://weiyc.github.io">Yunchao Wei</a>, <strong>Jianbo Jiao</strong></font><br>
<font size=2><em>IEEE/CVF Winter Conference on Applications of Computer Vision</em> (<strong>WACV</strong>), <font color=#FF8080><strong>Oral Presentation (2.5% of accepted papers)</strong></font>, 2024</font><br>
<a href="pdfs/wacv24dpt.pdf">[PDF]</a> <a href="bibs/wacv24dpt.bib">[BibTeX]</a> <a href="https://github.com/crystraldo/dpt">[Code]</a> <a href="https://crystraldo.github.io/dpt_mat/">[Project Page]</a>
<br></p>

<p><img align="left" style="width:200px;height:100px;margin:5px 5px" src="img/wacv24med.png">
<strong>FreMIM: Fourier Transform Meets Masked Image Modeling for Medical Image Segmentation</strong><br>
<font size=2>Wenxuan Wang*, Jing Wang*, Chen Chen,  <strong>Jianbo Jiao</strong>, Yuanxiu Cai, Shanshan Song, Jiangyun Li</font><br>
<font size=2><em>IEEE/CVF Winter Conference on Applications of Computer Vision</em> (<strong>WACV</strong>), 2024</font><br>
<a href="pdfs/wacv24med.pdf">[PDF]</a> <a href="bibs/wacv24med.bib">[BibTeX]</a> <a href="https://github.com/Rubics-Xuan/FreMIM">[Code]</a> <a href="https://rubics-xuan.github.io/FreMIM/">[Project Page]</a>
<br></p>

<p><img align="left" style="width:200px;height:100px;margin:5px 5px" src="img/acmmm24.png">
<strong>Frame Interpolation with Consecutive Brownian Bridge Diffusion</strong><br>
<font size=2>Zhonglin Lyu, Ming Li, <strong>Jianbo Jiao</strong>, Chen Chen</font><br>
<font size=2><em>ACM Multimedia</em> (<strong>ACM MM</strong>), 2024</font><br>
<a href="https://arxiv.org/pdf/2405.05953">[PDF]</a> <a href="bibs/acmmm24.bib">[BibTeX]</a> <a href="https://github.com/ZonglinL/ConsecutiveBrownianBridge">[Code]</a> <a href="https://zonglinl.github.io/videointerp/">[Project Page]</a>
<br></p>

<p><img align="left" style="width:200px;height:120px;margin:5px 5px" src="img/tip24_surfacesos.png">
<strong>Surface-SOS: Self-Supervised Object Segmentation via Neural Surface Representation</strong><br>
<font size=2> Xiaoyun Zheng, Liwei Liao, <strong>Jianbo Jiao</strong>, Feng Gao, Ronggang Wang</font><br>
<font size=2><em>IEEE Transactions on Image Processing</em>  (<strong>T-IP</strong>), 2024</font><br>
<a href="pdfs/tip24_surfacesos.pdf">[PDF]</a> <a href="bibs/tip24_surfacesos.bib">[BibTeX]</a> <a href="https://github.com/zhengxyun/Surface-SOS">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:100px;margin:5px 5px" src="img/midl24.png">
<strong>Med-Tuning: A New Parameter-Efficient Tuning Framework for Medical Volumetric Segmentation</strong><br>
<font size=2>Jiachen Shen*, Wenxuan Wang*, Chen Chen,  <strong>Jianbo Jiao</strong>, Jing Liu, Yan Zhang, Shanshan Song, Jiangyun Li</font><br>
<font size=2><em>Medical Imaging with Deep Learning</em> (<strong>MIDL</strong>), 2024</font><br>
<a href="https://arxiv.org/abs/2304.10880">[PDF]</a> <a href="bibs/midl24.bib">[BibTeX]</a> <a href="https://github.com/jessie-chen99/Med-Tuning-Official">[Code]</a> <a href="https://rubics-xuan.github.io/Med-Tuning/">[Project Page]</a>
<br></p>

<p><img align="left" style="width:200px;height:105px;margin:5px 5px" src="img/ISBI24.png">
<strong>Dual Representation Learning from Fetal Ultrasound Video and Sonographer Audio</strong><br>
<font size=2>Mourad Gridach, Mohammad Alsharid, <strong>Jianbo Jiao</strong>, Lior Drukker, Aris Papageorghiou, <a href="http://www.ibme.ox.ac.uk/research/biomedia/people/professor-alison-noble">Alison Noble</a></font><br>
<font size=2><em>IEEE International Symposium on Biomedical Imaging</em> (<strong>ISBI</strong>), <font color=#FF8080><strong>Oral Presentation</strong></font>, 2024</font><br>
<a href="pdfs/ISBI24.pdf">[PDF]</a> <a href="bibs/ISBI24.bib">[BibTeX]</a>
<br></p>

<p><img align="left" style="width:200px;height:100px;margin:5px 5px" src="img/ijcv23.png">
<strong>Inferring Attention Shifts for Salient Instance Ranking</strong><br>
<font size=2>Avishek Siris, <strong>Jianbo Jiao</strong>, Gary K.L. Tam, Xianghua Xie, Rynson W.H. Lau</font><br>
<font size=2><em>International Journal of Computer Vision</em> (<strong>IJCV</strong>), 2023</font><br>
<!-- <font size=2>This paper subsumes our [preliminary work](pdfs/CVPR20.pdf) presented at CVPR 2020.</font><br> -->
<a href="https://link.springer.com/article/10.1007/s11263-023-01906-7">[Article]</a> <a href="bibs/ijcv23.bib">[BibTeX]</a> <a href="https://github.com/SirisAvishek/Attention_Shift_Ranks">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:100px;margin:5px 5px" src="img/iccv23med.png">
<strong>Multi-view Self-supervised Disentanglement for General Image Denoising</strong><br>
<font size=2><a href="https://chqwer2.github.io/">Hao Chen</a>*, <a href="https://chenyuanqu.com/">Chenyuan Qu</a>*, Yu Zhang, Chen Chen, <strong>Jianbo Jiao</strong></font><br>
<font size=2><em>IEEE/CVF International Conference on Computer Vision</em> (<strong>ICCV</strong>), 2023</font><br>
<a href="pdfs/iccv23_med.pdf">[PDF]</a> <a href="https://arxiv.org/abs/2309.05049">[ArXiv]</a> <a href="bibs/iccv23_med.bib">[BibTeX]</a> <a href="https://github.com/chqwer2/Multi-view-Self-supervised-Disentanglement-Denoising">[Code]</a> <a href="https://chqwer2.github.io/MeD/">[Project Page]</a>
<br></p>

<p><img align="left" style="width:200px;height:108px;margin:5px 5px" src="img/iccv23coinseg.png">
<strong>CoinSeg: Contrast Inter- and Intra- Class Representations for Incremental Segmentation</strong><br>
<font size=2>Zekang Zhang, Guangyu Gao, <strong>Jianbo Jiao</strong>, Chi Harold Liu, <a href="https://weiyc.github.io">Yunchao Wei</a></font><br>
<font size=2><em>IEEE/CVF International Conference on Computer Vision</em> (<strong>ICCV</strong>), 2023</font><br>
<a href="pdfs/iccv23_coinseg.pdf">[PDF]</a> <a href="bibs/iccv23_coinseg.bib">[BibTeX]</a> <a href="https://github.com/zkzhang98/CoinSeg">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:115px;margin:5px 5px" src="img/iccv23clmvs.png">
<strong>CL-MVSNet: Unsupervised Multi-view Stereo with Dual-level Contrastive Learning</strong><br>
<font size=2>Kaiqiang Xiong, Rui Peng, Zhe Zhang, Tianxing Feng, <strong>Jianbo Jiao</strong>, Feng Gao, <a href="http://www.ece.pku.edu.cn/index.php?a=show&amp;catid=507&amp;id=48">Ronggang Wang</a></font><br>
<font size=2><em>IEEE/CVF International Conference on Computer Vision</em> (<strong>ICCV</strong>), 2023</font><br>
<a href="pdfs/iccv23_clmvs.pdf">[PDF]</a> <a href="bibs/iccv23_clmvs.bib">[BibTeX]</a> <a href="https://github.com/KaiqiangXiong/CL-MVSNet">[Code]</a> <a href="https://kaiqiangxiong.github.io/CL-MVSNet/">[Project Page]</a>
<br></p>

<p><img align="left" style="width:200px;height:100px;margin:5px 5px" src="img/iccv23diffuse3d.png">
<strong>Diffuse3D: Wide-Angle 3D Photography via Bilateral Diffusion</strong><br>
<font size=2>Yutao Jiang, Yang Zhou, Yuan Liang, Wenxi Liu, <strong>Jianbo Jiao</strong>, Yuhui Quan, <a href="http://www.shengfenghe.com/">Shengfeng He</a></font><br>
<font size=2><em>IEEE/CVF International Conference on Computer Vision</em> (<strong>ICCV</strong>), 2023</font><br>
<a href="pdfs/iccv23_diffuse3d.pdf">[PDF]</a> <a href="bibs/iccv23_diffuse3d.bib">[BibTeX]</a> <a href="https://github.com/yutaojiang1/Diffuse3D">[Code]</a> <a href="https://www.dropbox.com/scl/fi/zhp8q7ertpo49cd1t0hp4/d3d-video.mp4?rlkey=c66kkavd6j7d9ftwye1c2au1a&amp;dl=0">[Video]</a>
<br></p>

<p><img align="left" style="width:200px;height:108px;margin:5px 5px" src="img/bibm.png">
<strong>Bridging the Gap: Cross-modal Knowledge Driven Network for Radiology Report Generation</strong><br>
<font size=2>Beichen Kang, Yun Xiong, <strong>Jianbo Jiao</strong>, Yao Zhang, Xing Jia, Ji Li</font><br>
<font size=2><em>IEEE International Conference on Bioinformatics and Biomedicine</em> (<strong>BIBM</strong>), 2023</font><br>
<a href="pdfs/bibm.pdf">[PDF]</a> <a href="bibs/bibm.bib">[BibTeX]</a> <a href="https://github.com/Kangbeichen/CKNet">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:100px;margin:5px 5px" src="img/softinfo.png">
<strong>Speed Co-Augmentation for Unsupervised Audio-Visual Pre-training</strong><br>
<font size=2><a href="https://laura-wang.github.io/">Jiangliu Wang</a>, <strong>Jianbo Jiao</strong>, <a href="https://ybsong00.github.io">Yibing Song</a>, <a href="https://stepjam.github.io/">Stephen James</a>, Zhan Tong, Chongjian Ge, <a href="https://people.eecs.berkeley.edu/~pabbeel/">Pieter Abbeel</a>, Yun-Hui Liu </font><br>
<font size=2><em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<strong>CVPR</strong>) <a href="https://sightsound.org/"><em>Workshop on Sight and Sound</em></a>, 2023</font><br>
<a href="pdfs/softinfo.pdf">[PDF]</a> <a href="bibs/softinfo.bib">[BibTeX]</a> <a href="./">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:100px;margin:5px 5px" src="img/calince.png">
<strong>Cali-NCE: Boosting Cross-modal Video Representation Learning with Calibrated Alignment</strong><br>
<font size=2><a href="http://nxzhao.com/#">Nanxuan Zhao</a>, <strong>Jianbo Jiao</strong>, <a href="https://weidixie.github.io/index.html">Weidi Xie</a>, <a href="http://dahua.site/">Dahua Lin</a> </font><br>
<font size=2><em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<strong>CVPR</strong>) <a href="https://foundation-model.com/home"><em>Workshop on Foundation Model</em></a>, 2023</font><br>
<a href="pdfs/calince.pdf">[PDF]</a> <a href="bibs/calince.bib">[BibTeX]</a> <a href="https://github.com/nanxuanzhao/Cali-NCE">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:110px;margin:5px 5px" src="img/linr.png">
<strong>Revisiting Implicit Neural Representations in Low-Level Vision</strong><br>
<font size=2>Wentian Xu, <strong>Jianbo Jiao</strong> </font><br>
<font size=2><em>International Conference on Learning Representations</em> (<strong>ICLR</strong>) <a href="https://sites.google.com/view/neural-fields"><em>Neural Fields Workshop</em></a>, 2023</font><br>
<a href="pdfs/linr.pdf">[PDF]</a> <a href="https://arxiv.org/abs/2304.10250">[arXiv]</a> <a href="bibs/linr.bib">[BibTeX]</a> <a href="https://wentxul.github.io/LINR-projectpage/">[Project]</a>
<br></p>

<p><img align="left" style="width:200px;height:100px;margin:5px 5px" src="img/tml4h23.png">
<strong>A Kernel Density Estimation based Quality Metric for Quality Assessment of Obstetric Ultrasound Video</strong><br>
<font size=2>Jong Kwon, <strong>Jianbo Jiao</strong>, Alice Self, J. Alison Noble, Aris Papageorghiou </font><br>
<font size=2><em>International Conference on Learning Representations</em> (<strong>ICLR</strong>) <a href="https://sites.google.com/view/tml4h2023/home"><em>Trustworthy Machine Learning for Healthcare Workshop</em></a>, 2023</font><br>
<a href="pdfs/tml4h.pdf">[PDF]</a> <a href="bibs/tml4h.bib">[BibTeX]</a> <a href="https://github.com/kwon-j/KDE-UltrasoundQA">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:100px;margin:5px 5px" src="img/neurips22.png">
<strong>Mining Unseen Classes via Regional Objectness: A Simple Baseline for Incremental Segmentation</strong><br>
<font size=2>Zekang Zhang, Guangyu Gao, Zhiyuan Fang, <strong>Jianbo Jiao</strong>, <a href="https://weiyc.github.io">Yunchao Wei</a> </font><br>
<font size=2><em>Conference on Neural Information Processing Systems</em> (<strong>NeurIPS</strong>), 2022</font><br>
<a href="https://openreview.net/pdf?id=G1vrYk9uX-_">[PDF]</a> <a href="bibs/neurips22.bib">[BibTeX]</a> <a href="https://github.com/zkzhang98/MicroSeg">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:100px;margin:5px 5px" src="img/eccvw22.png">
<strong>Anatomy-Aware Contrastive Representation Learning for Fetal Ultrasound</strong><br>
<font size=2>Zeyu Fu*, <strong>Jianbo Jiao*</strong>, Robail Yasrab*, Lior Drukker, Aris T. Papageorghiou, <a href="http://www.ibme.ox.ac.uk/research/biomedia/people/professor-alison-noble">Alison Noble</a> (*Equal contribution)</font><br>
<font size=2><em>European Conference on Computer Vision</em> (<strong>ECCV</strong>) <em>Medical Computer Vision Workshop</em>, <font color=#FF8080><strong>Oral Presentation</strong></font> [<i class="fas fa-trophy"></i><a href="img/ECCV_MCV_BestPaperAward.jpeg"><font color="e63946"><strong>Best Paper Award</strong></font></a>], 2022</font><br>
<!-- [[PDF]](pdfs/awcl.pdf) [[BibTeX]](bibs/awcl.bib) -->
<a href="pdfs/awcl.pdf">[PDF]</a> <a href="bibs/awcl.bib">[BibTeX]</a> <a href="https://github.com/JianboJiao/AWCL">[Project]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/bmvc21.gif">
<strong>Quantised Transforming Auto-Encoders: Achieving Equivariance to Arbitrary Transformations in Deep Networks</strong><br>
<font size=2><strong>Jianbo Jiao</strong>, <a href="https://www.robots.ox.ac.uk/~joao/">João F. Henriques</a></font><br>
<font size=2><em>British Machine Vision Conference</em> (<strong>BMVC</strong>), 2021</font><br>
<a href="pdfs/bmvc21_qtae.pdf">[PDF]</a> <a href="bibs/bmvc21_qtae.bib">[BibTeX]</a> <a href="https://youtu.be/3Vm5gwfWTro">[Presentation]</a> <a href="https://www.robots.ox.ac.uk/~vgg/research/qtae/">[Project]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/medneurips.png">
<strong>Explainability of Self-Supervised Representation Learning for Medical Ultrasound Video</strong><br>
<font size=2>Kangning Zhang, <strong>Jianbo Jiao</strong>, <a href="http://www.ibme.ox.ac.uk/research/biomedia/people/professor-alison-noble">Alison Noble</a></font><br>
<font size=2><em>Conference on Neural Information Processing Systems Workshop</em> (<a href="https://sites.google.com/view/med-neurips-2021"><em>MedNeurIPS</em></a>), 2021</font><br>
<a href="pdfs/medneurips.pdf">[PDF]</a> <a href="bibs/medneurips.bib">[BibTeX]</a> <a href="srcs/medneurips_poster.jpeg">[Poster]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/tpami21.png">
<strong>Self-Supervised Video Representation Learning by Uncovering Spatio-temporal Statistics</strong><br>
<font size=2><a href="https://laura-wang.github.io/">Jiangliu Wang*</a>, <strong>Jianbo Jiao</strong>*, <a href="https://sites.google.com/site/linchaobao/">Linchao Bao</a>, <a href="http://www.shengfenghe.com/">Shengfeng He</a>, <a href="http://www.ee.columbia.edu/~wliu/">Wei Liu</a>, <a href="http://ri.cuhk.edu.hk/yhliu">Yunhui Liu</a> (*Equal contribution)</font><br>
<font size=2><em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> (<strong>T-PAMI</strong>), 2021</font><br>
<font size=2>This paper subsumes our <a href="pdfs/cvpr_VidMAS.pdf">preliminary work</a> presented at CVPR 2019, with <font color=#FF8080><strong>~30%</strong></font> performance improvement!</font><br>
<a href="pdfs/tpami21.pdf">[PDF]</a> <a href="bibs/tpami21.bib">[BibTeX]</a> <a href="https://github.com/laura-wang/video_repres_sts">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:100px;margin:5px 5px" src="img/neurips21.png">
<strong>Revitalizing CNN Attentions via Transformers in Self-Supervised Visual Representation Learning</strong><br>
<font size=2>Chongjian Ge, Youwei Liang, <a href="https://ybsong00.github.io">Yibing Song</a>, <strong>Jianbo Jiao</strong>, <a href="https://www.juew.org">Jue Wang</a>, <a href="http://luoping.me/">Ping Luo</a> </font><br>
<font size=2><em>Conference on Neural Information Processing Systems</em> (<strong>NeurIPS</strong>), 2021</font><br>
<a href="https://arxiv.org/abs/2110.05340">[PDF]</a> <a href="bibs/neurips21.bib">[BibTeX]</a> <a href="https://github.com/ChongjianGE/CARE">[Project]</a> <a href="https://openreview.net/forum?id=sRojdWhXJx">[OpenReview]</a> <a href="https://mp.weixin.qq.com/s/oGS4XSjO29fHdDQXV1vyvg">[Media Coverage]</a>
<br></p>

<p><img align="left" style="width:200px;height:100px;margin:5px 5px" src="img/iccv21.png">
<strong>Scene Context-Aware Salient Object Detection</strong><br>
<font size=2>Avishek Siris, <strong>Jianbo Jiao</strong>, Gary K.L. Tam, Xianghua Xie, <a href="http://www.cs.cityu.edu.hk/~rynson/">Rynson W.H. Lau</a></font><br>
<font size=2><em>IEEE/CVF International Conference on Computer Vision</em> (<strong>ICCV</strong>), 2021</font><br>
<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Siris_Scene_Context-Aware_Salient_Object_Detection_ICCV_2021_paper.pdf">[PDF]</a> <a href="bibs/ICCV21.bib">[BibTeX]</a> <a href="https://github.com/SirisAvishek/Scene_Context_Aware_Saliency">[Code and Dataset]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/jbhi.png">
<strong>Facial Anatomical Landmark Detection using Regularized Transfer Learning with Application to Fetal Alcohol Syndrome Recognition</strong><br>
<font size=2>Zeyu Fu, <strong>Jianbo Jiao</strong>, Michael Suttie, <a href="http://www.ibme.ox.ac.uk/research/biomedia/people/professor-alison-noble">Alison Noble</a></font><br>
<font size=2><em>IEEE Journal of Biomedical and Health Informatics</em> (<strong>JBHI</strong>), 2021</font><br>
<a href="https://ieeexplore.ieee.org/abstract/document/9531054">[PDF]</a> <a href="bibs/jbhi.bib">[BibTeX]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/tpami21_2.png">
<strong>Affinity Attention Graph Neural Network for Weakly Supervised Semantic Segmentation</strong><br>
<font size=2>Bingfeng Zhang, Jimin Xiao, <strong>Jianbo Jiao</strong>, <a href="https://weiyc.github.io">Yunchao Wei</a>,<a href="https://scholar.google.com/citations?user=474TbQYAAAAJ&amp;hl=en">Yao Zhao</a></font><br>
<font size=2><em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> (<strong>T-PAMI</strong>), 2021</font><br>
<a href="pdfs/tpami21_2.pdf">[PDF]</a> <a href="bibs/tpami21_2.bib">[BibTeX]</a> <a href="https://github.com/zbf1991/A2GNN">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/tip21.png">
<strong>Multi-View Face Synthesis via Progressive Face Flow</strong><br>
<font size=2>Yangyang Xu, Xuemiao Xu, <strong>Jianbo Jiao</strong>, Keke Li, Cheng Xu, <a href="sf">Shengfeng He</a></font><br>
<font size=2><em>IEEE Transactions on Image Processing</em> (<strong>T-IP</strong>), 2021</font><br>
<a href="https://ieeexplore.ieee.org/document/9466401">[PDF]</a> <a href="bibs/tip21.bib">[BibTeX]</a> <a href="./">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:105px;margin:5px 5px" src="img/MICCAI20.png">
<strong>Self-Supervised Contrastive Video-Speech Representation Learning for Ultrasound</strong><br>
<font size=2><strong>Jianbo Jiao</strong>, Yifan Cai, Mohammad Alsharid, Lior Drukker, Aris Papageorghiou, <a href="http://www.ibme.ox.ac.uk/research/biomedia/people/professor-alison-noble">Alison Noble</a></font><br>
<font size=2><em>International Conference on Medical Image Computing and Computer Assisted Intervention</em> (<strong>MICCAI</strong>), <font color=#FF8080><strong>Oral Presentation (Early Acceptance)</strong></font>, 2020</font><br>
<a href="pdfs/MICCAI20.pdf">[PDF]</a> <a href="bibs/MICCAI20.bib">[BibTeX]</a> <a href="https://youtu.be/gpCc8IMF2NE">[Presentation Video]</a> <a href="pdfs/MICCAI20_GA.pdf">[Graphical Abstract]</a> [<a href="https://www.rsipvision.com/MICCAI2020-Wednesday/6/">MICCAI Daily Coverage</a>, <a href="https://www.rsipvision.com/ComputerVisionNews-2020December/30/">Best of MICCAI 2020 Coverage</a>]
<!-- <a href="./" title="to appear">[PDF]</a> <a href="./" title="to appear">[BibTeX]</a> -->
<br></p>

<p><img align="left" style="width:200px;height:105px;margin:5px 5px" src="img/ECCV_unisal.png">
<strong>Unified Image and Video Saliency Modeling</strong><br>
<font size=2><a href="https://rdroste.com">Richard Droste*</a>, <strong>Jianbo Jiao</strong>*, <a href="http://www.ibme.ox.ac.uk/research/biomedia/people/professor-alison-noble">Alison Noble</a> (*Equal contribution)</font><br>
<font size=2><em>European Conference on Computer Vision</em> (<strong>ECCV</strong>), <font color=#FF8080><strong>Spotlight Presentation</strong></font>, 2020</font><br>
<a href="pdfs/ECCV_unisal.pdf">[PDF]</a> <a href="bibs/ECCV_unisal.bib">[BibTeX]</a> <a href="https://www.youtube.com/watch?v=k6AX_7Blu_s&amp;t=3s">[Short Video]</a> <a href="https://www.youtube.com/watch?v=9pnxkgLrceo&amp;t=8s">[Long Video]</a> <a href="https://www.youtube.com/watch?v=4CqMPDI6BqE">[More Results]</a> <a href="https://github.com/rdroste/unisal">[Project]</a>
<!-- <a href="./" title="to appear">[PDF]</a> <a href="./" title="to appear">[BibTeX]</a> [[Project]](https://github.com/rdroste/unisal) -->
<br></p>

<p><img align="left" style="width:200px;height:105px;margin:5px 5px" src="img/ECCV_pace.png">
<strong>Self-Supervised Video Representation Learning by Pace Prediction</strong><br>
<font size=2>Jiangliu Wang, <strong>Jianbo Jiao</strong>, Yun-Hui Liu</font><br>
<font size=2><em>European Conference on Computer Vision</em> (<strong>ECCV</strong>), 2020</font><br>
<a href="pdfs/ECCV_pace.pdf">[PDF]</a> <a href="bibs/ECCV_pace.bib">[BibTeX]</a> <a href="https://www.youtube.com/watch?v=wYHteK4BHlk&amp;feature=youtu.be">[Short Video]</a> <a href="https://www.youtube.com/watch?v=LCeJYkSFXSk">[Long Video]</a> <a href="https://github.com/laura-wang/video-pace">[Code]</a>
<!-- <a href="./" title="to appear">[PDF]</a> <a href="./" title="to appear">[BibTeX]</a> <a href="./" title="to appear">[Code]</a> -->
<br></p>

<p><img align="left" style="width:200px;height:115px;margin:5px 5px" src="img/TMI20.png">
<strong>Self-Supervised Ultrasound to MRI Fetal Brain Image Synthesis</strong><br>
<font size=2><strong>Jianbo Jiao</strong>, <a href="http://www.ibme.ox.ac.uk/research/biomedia/people/ana-ineda-l-namburete">Ana Namburete</a>, Aris Papageorghiou, <a href="http://www.ibme.ox.ac.uk/research/biomedia/people/professor-alison-noble">Alison Noble</a></font><br>
<font size=2><em>IEEE Transactions on Medical Imaging</em> (<strong>T-MI</strong>), 2020</font><br>
<font size=2>This paper subsumes our <a href="pdfs/MICCAI_MLMI.pdf">preliminary work</a> presented at MICCAI-MLMI 2019.</font><br>
<a href="pdfs/TMI20.pdf">[PDF]</a> <a href="bibs/TMI20.bib">[BibTeX]</a> <a href="https://bitbucket.org/JianboJiao/ssus2mri/">[Code]</a>
<!-- <a href="./" title="to appear">[PDF]</a> <a href="./" title="to appear">[BibTeX]</a> <a href="./" title="to appear">[Code]</a> -->
<br></p>

<p><img align="left" style="width:200px;height:105px;margin:5px 5px" src="img/ISBI20.png">
<strong>Self-Supervised Representation Learning for Ultrasound Video</strong><br>
<font size=2><strong>Jianbo Jiao</strong>, <a href="https://rdroste.com">Richard Droste</a>, Lior Drukker, Aris Papageorghiou, <a href="http://www.ibme.ox.ac.uk/research/biomedia/people/professor-alison-noble">Alison Noble</a></font><br>
<font size=2><em>IEEE International Symposium on Biomedical Imaging</em> (<strong>ISBI</strong>), 2020</font><br>
<a href="pdfs/ISBI20.pdf">[PDF]</a> <a href="bibs/ISBI20.bib">[BibTeX]</a>
<br></p>

<p><img align="left" style="width:200px;height:105px;margin:5px 5px" src="img/ACMMM20.png">
<strong>Tactile Sketch Saliency</strong><br>
<font size=2><strong>Jianbo Jiao</strong>, <a href="http://www.ying-cao.com">Ying Cao</a>, <a href="https://sites.google.com/site/manfredlau/">Manfred Lau</a>, <a href="http://www.cs.cityu.edu.hk/~rynson/">Rynson W.H. Lau</a></font><br>
<font size=2><em>ACM International Conference on Multimedia</em> (<strong>ACM MM</strong>), 2020</font><br>
<a href="pdfs/ACMMM20.pdf">[PDF]</a> <a href="bibs/ACMMM20.bib">[BibTeX]</a> <a href="https://bitbucket.org/JianboJiao/tactilesketchsaliency">[Data &amp; Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:100px;margin:5px 5px" src="img/CVPR20.png">
<strong>Inferring Attention Shift Ranks of Objects for Image Saliency</strong><br>
<font size=2>Avishek Siris, <strong>Jianbo Jiao</strong>, Gary K.L. Tam, Xianghua Xie, <a href="http://www.cs.cityu.edu.hk/~rynson/">Rynson W.H. Lau</a></font><br>
<font size=2><em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<strong>CVPR</strong>), 2020</font><br>
<a href="pdfs/CVPR20.pdf">[PDF]</a> <a href="bibs/CVPR20.bib">[BibTeX]</a> <a href="https://www.youtube.com/watch?v=vj2bhD7ZgS0">[Presentation Video]</a> <a href="https://github.com/SirisAvishek/Attention_Shift_Ranks">[Project]</a> <a href="https://cove.thecvf.com/datasets/325">[Dataset]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/AAAI.png">
<strong>When AWGN-based Denoiser Meets Real Noises</strong><br>
<font size=2><a href="https://yzhouas.github.io">Yuqian Zhou</a>, <strong>Jianbo Jiao</strong>, <a href="https://brotherhuang.github.io">Haibin Huang</a>, Yang Wang, <a href="https://www.juew.org">Jue Wang</a>, <a href="https://www.humphreyshi.com/">Honghui Shi</a>, <a href="http://ifp-uiuc.github.io">Thomas S. Huang</a></font><br>
<font size=2><em>AAAI Conference on Artificial Intelligence</em> (<strong>AAAI</strong>), <font color=#FF8080><strong>Spotlight Presentation</strong></font>, 2020</font><br>
<a href="pdfs/AAAI.pdf">[PDF]</a> <a href="bibs/AAAI.bib">[BibTeX]</a> <a href="https://github.com/yzhouas/PD-Denoising-pytorch">[Code]</a> <a href="https://github.com/kritiksoman/GIMP-ML/wiki/References">[GIMP-ML]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/mlmi20.png">
<strong>Cross-Task Representation Learning for Anatomical Landmark Detection</strong><br>
<font size=2>Zeyu Fu, <strong>Jianbo Jiao</strong>, Michael Suttie, <a href="http://www.ibme.ox.ac.uk/research/biomedia/people/professor-alison-noble">Alison Noble</a></font><br>
<font size=2><em>International Conference on Medical Image Computing and Computer Assisted Intervention</em> (<strong>MICCAI</strong>) <em>Workshop on</em> <strong>MLMI</strong>, 2020</font><br>
<a href="https://arxiv.org/pdf/2009.13635.pdf">[PDF]</a> <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:N1DbM4_WBcsJ:scholar.google.com/&amp;output=citation&amp;scisdr=CgWeAti1EJHgneRHSNE:AAGBfm0AAAAAYBdCUNFJidXtSUun7s2q1iN6kYUFH5Id&amp;scisig=AAGBfm0AAAAAYBdCUOecB_CF0wBpm4uFHfNKxPqhoWid&amp;scisf=4&amp;ct=citation&amp;cd=-1&amp;hl=en">[BibTeX]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/pippi.png">
<strong>Differentiating Operator Skill During Routine Fetal Ultrasound Scanning Using Probe Motion Tracking</strong><br>
<font size=2>Yipei Wang, <a href="https://rdroste.com/">Richard Droste</a>, <strong>Jianbo Jiao</strong>, Harshita Sharma, Lior Drukker, Aris T. Papageorghiou, <a href="http://www.ibme.ox.ac.uk/research/biomedia/people/professor-alison-noble">Alison Noble</a></font><br>
<font size=2><em>International Conference on Medical Image Computing and Computer Assisted Intervention</em> (<strong>MICCAI</strong>) <em>Workshop on</em> <strong>ASMUS</strong>, <font color=#FF8080><strong>Oral Presentation</strong></font>, 2020</font><br>
<a href="https://link.springer.com/chapter/10.1007/978-3-030-60334-2_18">[PDF]</a> <a href="https://scholar.googleusercontent.com/scholar.bib?q=info:B7bfC0Mlv6AJ:scholar.google.com/&amp;output=citation&amp;scisdr=CgWeAti1EJHgneRDLJU:AAGBfm0AAAAAYBdGNJVHpSOzvEC1Hk8y3_14FrtNquBY&amp;scisig=AAGBfm0AAAAAYBdGNGuOFlZ4GiHdQ9YOnZlnSWDInxcO&amp;scisf=4&amp;ct=citation&amp;cd=-1&amp;hl=en">[BibTeX]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/FormNet_TIP20.png">
<strong>FormNet: Formatted Learning for Image Restoration</strong><br>
<font size=2><strong>Jianbo Jiao</strong>, <a href="wc">Wei-Chih Tu</a>, <a href="https://scholar.google.com/citations?user=PGtHUI0AAAAJ&amp;hl=en">Ding Liu</a>, <a href="sf">Shengfeng He</a>,  <a href="rynson">Rynson Lau</a>, <a href="http://ifp-uiuc.github.io">Thomas S. Huang</a></font><br>
<font size=2><em>IEEE Transactions on Image Processing</em> (<strong>T-IP</strong>), 2020</font><br>
<font size=2>This paper subsumes our <a href="pdfs/cvprw.pdf">preliminary work</a> presented at CVPRW 2017.</font><br>
<a href="pdfs/tip_formnet.pdf">[PDF]</a> <a href="bibs/FormNet_TIP20.bib">[BibTeX]</a> <a href="https://bitbucket.org/JianboJiao/formnet">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/TIP20.png">
<strong>Connecting Image Denoising and High-Level Vision Tasks via Deep Learning</strong><br>
<font size=2><a href="https://scholar.google.com/citations?user=PGtHUI0AAAAJ&amp;hl=en">Ding Liu</a>, <a href="http://bihanwen.ece.illinois.edu">Bihan Wen</a>, <strong>Jianbo Jiao</strong>, <a href="https://scholar.google.com/citations?user=697UEEIAAAAJ&amp;hl=en">Xianming Liu</a>, <a href="https://www.atlaswang.com">Zhangyang Wang</a>, <a href="http://ifp-uiuc.github.io">Thomas S. Huang</a></font><br>
<font size=2><em>IEEE Transactions on Image Processing</em> (<strong>T-IP</strong>), 2020</font><br>
<a href="pdfs/tip_connecting.pdf">[PDF]</a> <a href="bibs/TIP20.bib">[BibTeX]</a> <a href="https://github.com/Ding-Liu/DeepDenoising">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:105px;margin:5px 5px" src="img/MICCAI_MLMI19.png">
<strong>Anatomy-Aware Self-Supervised Fetal MRI Synthesis from Unpaired Ultrasound Images</strong><br>
<font size=2><strong>Jianbo Jiao</strong>, <a href="http://www.ibme.ox.ac.uk/research/biomedia/people/ana-ineda-l-namburete">Ana Namburete</a>, Aris Papageorghiou, <a href="http://www.ibme.ox.ac.uk/research/biomedia/people/professor-alison-noble">Alison Noble</a></font><br>
<font size=2><em>International Conference on Medical Image Computing and Computer Assisted Intervention</em> (<strong>MICCAI</strong>) <em>Workshop on Machine Learning in Medical Imaging (<a href="http://mlmi2019.web.unc.edu">MLMI</a>)</em>, <font color=#FF8080><strong>Oral Presentation</strong></font>, 2019</font><br>
<a href="pdfs/MICCAI_MLMI.pdf">[PDF]</a> <a href="bibs/MICCAI_MLMI.bib">[BibTeX]</a> <a href="srcs/miccai_mlmi.ppsm">[Presentation]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/cvpr19.png">
<strong>Geometry-Aware Distillation for Indoor Semantic Segmentation</strong><br>
<font size=2><strong>Jianbo Jiao</strong>, <a href="https://weiyc.github.io">Yunchao Wei</a>, <a href="http://jiezequn.me">Zequn Jie</a>, <a href="https://www.humphreyshi.com/">Honghui Shi</a>, <a href="http://www.cs.cityu.edu.hk/~rynson/">Rynson W.H. Lau</a>, <a href="http://ifp-uiuc.github.io">Thomas S. Huang</a></font><br>
<font size=2><em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<strong>CVPR</strong>), 2019</font><br>
<a href="pdfs/cvpr_GAD.pdf">[PDF]</a> <a href="bibs/cvpr_GAD.bib">[BibTeX]</a> <a href="https://bitbucket.org/JianboJiao/semseggap/src/master/">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/cvpr19_2.png">
<strong>Self-Supervised Spatio-temporal Representation Learning for Videos by Predicting Motion and Appearance Statistics</strong><br>
<font size=2>Jiangliu Wang, <strong>Jianbo Jiao</strong>, <a href="https://sites.google.com/site/linchaobao/">Linchao Bao</a>, <a href="http://www.shengfenghe.com/">Shengfeng He</a>, Yunhui Liu, <a href="http://www.ee.columbia.edu/~wliu/">Wei Liu</a></font><br>
<font size=2><em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<strong>CVPR</strong>), 2019</font><br>
<!-- <a href="./" title="to appear">[PDF]</a> -->
<a href="pdfs/cvpr_VidMAS.pdf">[PDF]</a> <a href="bibs/cvpr_VidMAS.bib">[BibTeX]</a> <a href="https://github.com/laura-wang/video_repres_mas">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/ACMMM.png">
<strong>Ground-Aware Point Cloud Semantic Segmentation for Autonomous Driving</strong><br>
<font size=2>Jian Wu, <strong>Jianbo Jiao</strong>, <a href="https://sites.google.com/site/itrymanytimes/home">Qingxiong Yang</a>, Zheng-Jun Zha, <a href="http://staff.ustc.edu.cn/~xjchen99/">Xuejin Chen</a></font><br>
<font size=2><em>ACM International Conference on Multimedia</em> (<strong>ACM MM</strong>), <font color=#FF8080><strong>Oral Presentation</strong></font>, 2019</font><br>
<a href="pdfs/ACMMM.pdf">[PDF]</a> <a href="bibs/ACMMM.bib">[BibTeX]</a> <a href="http://www.moonx.ai/#/open">[Project]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/TCBB.png">
<strong>Few-shot Breast Cancer Metastases Classification via Unsupervised Cell Ranking</strong><br>
<font size=2>Jiaojiao Chen, <strong>Jianbo Jiao</strong>, <a href="http://www.shengfenghe.com/">Shengfeng He</a>, Guoqiang Han, <a href="https://sn.polyu.edu.hk/en/people/academic_staff/index.html#harry.qin">Jing Qin</a></font><br>
<font size=2><em>IEEE Transactions on Computational Biology and Bioinformatics</em> (<strong>T-CBB</strong>), 2019</font><br>
<a href="pdfs/TCBB.pdf">[PDF]</a> <a href="bibs/TCBB.bib">[BibTeX]</a> <a href="https://github.com/jiaojiao-Chen/fewshot-camelyon">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/TIP.png">
<strong>Stereoscopic Image Generation from Light Field with Disparity Scaling and Super-Resolution</strong><br>
<font size=2>Tao Yan, <strong>Jianbo Jiao</strong>, Wenxi Liu, <a href="http://www.cs.cityu.edu.hk/~rynson/">Rynson W.H. Lau</a></font><br>
<font size=2><em>IEEE Transactions on Image Processing</em> (<strong>T-IP</strong>), 2019</font><br>
<a href="pdfs/TIP.pdf">[PDF]</a> <a href="bibs/TIP.bib">[BibTeX]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/TMM.png">
<strong>Referring Image Segmentation by Generative Adversarial Learning</strong><br>
<font size=2>Shuang Qiu, <a href="https://scholar.google.com/citations?user=474TbQYAAAAJ&amp;hl=en">Yao Zhao</a>, <strong>Jianbo Jiao</strong>, <a href="https://weiyc.github.io">Yunchao Wei</a>, Shikui Wei</font><br>
<font size=2><em>IEEE Transactions on Multimedia</em> (<strong>T-MM</strong>), 2019</font><br>
<a href="pdfs/TMM.pdf">[PDF]</a> <a href="bibs/TMM.bib">[BibTeX]</a>
<br></p>

<p><img align="left" style="width:200px;height:125px;margin:5px 5px" src="img/eccv.png">
<strong>Look Deeper into Depth: Monocular Depth Estimation with Semantic Booster and Attention-Driven Loss</strong><br>
<font size=2><strong>Jianbo Jiao</strong>, <a href="http://www.ying-cao.com">Ying Cao</a>, <a href="https://ybsong00.github.io">Yibing Song</a>, <a href="http://www.cs.cityu.edu.hk/~rynson/">Rynson W.H. Lau</a></font><br>
<font size=2><em>European Conference on Computer Vision</em> (<strong>ECCV</strong>), 2018</font><br>
<a href="pdfs/eccv_LDiD.pdf">[PDF]</a> <a href="bibs/eccv_LDiD.bib">[BibTeX]</a> <a href="https://bitbucket.org/JianboJiao/ldid/src/master/">[Code]</a>
<br></p>

<p><img align="left" style="width:200px;height:105px;margin:5px 5px" src="img/eccv_web.png">
<strong>Task-Driven Webpage Saliency</strong><br>
<font size=2><a href="https://quanlzheng.github.io">Quanlong Zheng</a>, <strong>Jianbo Jiao</strong>, <a href="http://www.ying-cao.com">Ying Cao</a>, <a href="http://www.cs.cityu.edu.hk/~rynson/">Rynson W.H. Lau</a></font><br>
<font size=2><em>European Conference on Computer Vision</em> (<strong>ECCV</strong>), 2018</font><br>
<a href="pdfs/eccv_TDSal.pdf">[PDF]</a> <a href="bibs/eccv_TDSal.bib">[BibTeX]</a> <a href="https://quanlzheng.github.io/projects/Task-driven-Webpage-Saliency.html">[Project]</a>
<br></p>

<p><img align="left" style="width:200px;height:105px;margin:5px 5px" src="img/iccv.png">
<strong>Delving into Salient Object Subitizing and Detection</strong><br>
<font size=2><a href="http://www.shengfenghe.com/">Shengfeng He</a>, <strong>Jianbo Jiao</strong>, Xiaodan Zhang, <a href="http://cs.scut.edu.cn/jxgl/yjsjy/dsjj/bshshdsh/17gh4u6trjjd6.xhtml">Guoqiang Han</a>, <a href="http://www.cs.cityu.edu.hk/~rynson/">Rynson W.H. Lau</a></font><br>
<font size=2><em>IEEE International Conference on Computer Vision</em> (<strong>ICCV</strong>), 2017</font><br>
<a href="pdfs/iccv.pdf">[PDF]</a> <a href="bibs/iccv.bib">[BibTeX]</a></p>

<p><img align="left" style="width:200px;height:105px;margin:5px 5px" src="img/ijcv.png">
<strong>Joint Image Denoising and Disparity Estimation via Stereo Structure PCA and Noise-Tolerant Cost</strong><br>
<font size=2><strong>Jianbo Jiao</strong>, <a href="https://sites.google.com/site/itrymanytimes/home">Qingxiong Yang</a>, <a href="http://www.shengfenghe.com/">Shengfeng He</a>, <a href="https://sites.google.com/site/shuhanggu/home">Shuhang Gu</a>, <a href="http://www4.comp.polyu.edu.hk/~cslzhang/">Lei Zhang</a>, <a href="http://www.cs.cityu.edu.hk/~rynson/">Rynson W. H. Lau</a></font><br>
<font size=2><em>International Journal of Computer Vision</em> (<strong>IJCV</strong>), 2017</font><br>
<a href="pdfs/ijcv.pdf">[PDF]</a> <a href="bibs/ijcv.bib">[BibTeX]</a> <a href="https://bitbucket.org/JianboJiao/jointstereodn/src/master/">[Code]</a> <a href="https://drive.google.com/file/d/1yjQs_fH7SQ-7pSLigklUkNH96SovghWG/view?usp=sharing">[Data]</a></p>

<p><img align="left" img style="width:200px;height:105px;margin:5px 5px" src="img/cvprw.png">
<strong>FormResNet: Formatted Residual Learning for Image Restoration</strong><br>
<font size=2><strong>Jianbo Jiao</strong>, <a href="https://sites.google.com/site/wctu1009/">Wei-Chih Tu</a>, <a href="http://www.shengfenghe.com/">Shengfeng He</a>, <a href="http://www.cs.cityu.edu.hk/~rynson/">Rynson W. H. Lau</a></font><br>
<font size=2><em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<strong>CVPR</strong>) <em>Workshop (<a href="http://www.vision.ee.ethz.ch/ntire17/">NTIRE</a>)</em>, <font color=#FF8080><strong>Oral Presentation</strong></font>, 2017</font><br>
<a href="pdfs/cvprw.pdf">[PDF]</a> <a href="bibs/cvprw.bib">[BibTeX]</a> <a href="https://bitbucket.org/JianboJiao/formresnet/src/master/">[Code]</a> <a href="srcs/cvprw_slid.ppsm">[Slides]</a> <a href="srcs/cvprw_pos.pdf">[Poster]</a></p>

<p><img align="left" style="width:200px;height:105px;margin:5px 5px" src="img/icip.png">
<strong>A Hand Pose Tracking Benchmark From Stereo Matching</strong><br>
<font size=2><a href="https://sites.google.com/site/zhjw1988/">Jiawei Zhang</a>, <strong>Jianbo Jiao</strong>, <a href="http://www.cs.cityu.edu.hk/~mlchen2/">Mingliang Chen</a>, <a href="http://vision.sia.cn/our%20team/QuLiangqun-homepage/vision-Quliangqiong(English).html">Liangqiong Qu</a>, <a href="http://www.cs.cityu.edu.hk/~xiaobinxu2/">Xiaobin Xu</a>, <a href="https://sites.google.com/site/itrymanytimes/home">Qingxiong Yang</a></font><br>
<font size=2><em>IEEE International Conference on Image Processing</em> (<strong>ICIP</strong>), <font color=#FF8080><strong>Oral Presentation</strong></font>, 2017</font><br>
<a href="pdfs/icip.pdf">[PDF]</a> <a href="https://arxiv.org/pdf/1610.07214.pdf">[Tech Report]</a> <a href="bibs/icip.bib">[BibTeX]</a> [<a href="https://github.com/zhjwustc/icip17_stereo_hand_pose_dataset">Data</a>: <a href="https://www.dropbox.com/sh/g13petlurikkivo/AACgwsoKsbtzMxX_e6bhH39Qa?dl=0">Dropbox</a>, <a href="https://www.google.com/url?q=https%3A%2F%2Fportland-my.sharepoint.com%2F%3Af%3A%2Fg%2Fpersonal%2Fjiawzhang8-c_my_cityu_edu_hk%2FEkznohE3YL1Jk8igTCQ4HqYBg_9WJi9hWAetybea9o3iMQ%3Fe%3DkcbMmj&amp;sa=D&amp;sntz=1&amp;usg=AFQjCNGxPD4n-BZYzVcEQ0mmFIwFCz7DaQ">OneDrive</a>]</p>

<p><img align="left" style="width:200px;height:105px;margin:5px 5px" src="img/tcsvt.png">
<strong>Color Image Guided Boundary-inconsistent Region Refinement for Stereo Matching</strong><br>
<font size=2><strong>Jianbo Jiao</strong>, <a href="http://www.ece.pku.edu.cn/index.php?a=show&amp;catid=507&amp;id=48">Ronggang Wang</a>, <a href="http://www.ece.pku.edu.cn/index.php?a=show&amp;catid=507&amp;id=42">Wenmin Wang</a>, <a href="https://www.researchgate.net/profile/Dagang_Li">Dagang Li</a>, <a href="http://www.jdl.ac.cn/htm-gaowen/">Wen Gao</a></font><br>
<font size=2><em>IEEE Transactions on Circuits and Systems for Video Technology</em> (<strong>T-CSVT</strong>), 2015</font><br>
<a href="pdfs/tcsvt.pdf">[PDF]</a> <a href="bibs/tcsvt.bib">[BibTeX]</a> <a href="https://bitbucket.org/JianboJiao/disprefine/src/master/">[Code]</a></p>

<p><img align="left" style="width:200px;height:105px;margin:5px 5px" src="img/mm.png">
<strong>Local Stereo Matching with Improved Matching Cost and Disparity Refinement</strong><br>
<font size=2><strong>Jianbo Jiao</strong>, <a href="http://www.ece.pku.edu.cn/index.php?a=show&amp;catid=507&amp;id=48">Ronggang Wang</a>, <a href="http://www.ece.pku.edu.cn/index.php?a=show&amp;catid=507&amp;id=42">Wenmin Wang</a>, <a href="https://www.researchgate.net/profile/Shengfu_Dong">Shengfu Dong</a>, <a href="https://www.researchgate.net/profile/Zhenyu_Wang38">Zhenyu Wang</a>, <a href="http://www.jdl.ac.cn/htm-gaowen/">Wen Gao</a></font><br>
<font size=2><em>IEEE Multimedia</em>, 2014</font><br>
<a href="pdfs/mm.pdf">[PDF]</a> <a href="bibs/MM.bib">[BibTeX]</a></p>

<p><img align="left" style="width:200px;height:105px;margin:5px 5px" src="img/icme.png">
<strong>Cost-Volume Filtering-Based Stereo Matching with Improved Matching Cost and Secondary Refinement</strong><br>
<font size=2><strong>Jianbo Jiao</strong>, <a href="http://www.ece.pku.edu.cn/index.php?a=show&amp;catid=507&amp;id=48">Ronggang Wang</a>, <a href="http://www.ece.pku.edu.cn/index.php?a=show&amp;catid=507&amp;id=42">Wenmin Wang</a>, <a href="https://www.researchgate.net/profile/Shengfu_Dong">Shengfu Dong</a>, <a href="https://www.researchgate.net/profile/Zhenyu_Wang38">Zhenyu Wang</a>, <a href="http://www.jdl.ac.cn/htm-gaowen/">Wen Gao</a></font><br>
<font size=2><em>IEEE International Conference on Multimedia and Expo</em> (<strong>ICME</strong>), <font color=#FF8080><strong>Oral Presentation</strong></font> [<i class="fas fa-trophy"></i><font color="red"><strong>Best Student Paper</strong></font> candidate], 2014</font><br>
<a href="pdfs/icme.pdf">[PDF]</a> <a href="bibs/icme.bib">[BibTeX]</a> <a href="srcs/icme_slid.ppsm">[Slides]</a> <a href="srcs/icme_pos.pdf">[Poster]</a> <a href="https://youtu.be/w6jJu3GXPVY">[demo]</a></p>

					</section>

			

      <div class="footer">
	<hr class="thin" />
	<div class="pure-menu pure-menu-horizontal pure-menu-open">
		<ul class="footer-menu">
		
			
			<li><a href="/"><i class="fa fa-home" aria-hidden="true"></i></a></li>
		
		</ul>
	</div>

	
	<p>&copy; 2025, JianboJiao. All rights reserved. </p>
	<p>Credits <a href="https://github.com/tmaiaroto/hugo-redlounge" target="_blank">Red Lounge</a> and <a href="https://gohugo.io" target="_blank">Hugo</a>.</p>
</div>

    </div>
  </div>
	

	

  
</body>
</html>
